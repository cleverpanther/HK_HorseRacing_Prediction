{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Horse Race Prediction\n",
    "## Regression Modelling\n",
    "- In this section, we want to predict the finishing times of horses in a race, and then use it to predict the winner.\n",
    "- We will use RMSE to evaluate, then after classification of the horse with the fastest time, find the accuracy of our prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import f1_score, roc_curve, auc, confusion_matrix, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "import time\n",
    "import joblib\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the train and test files\n",
    "df_train = pd.read_csv('./data/df_train.csv')\n",
    "df_test = pd.read_csv('./data/df_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23500, 27)\n",
      "(5864, 27)\n"
     ]
    }
   ],
   "source": [
    "# View the shape of the train and test files\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>finishing_position</th>\n",
       "      <th>horse_number</th>\n",
       "      <th>horse_name</th>\n",
       "      <th>horse_id</th>\n",
       "      <th>jockey</th>\n",
       "      <th>trainer</th>\n",
       "      <th>actual_weight</th>\n",
       "      <th>declared_horse_weight</th>\n",
       "      <th>draw</th>\n",
       "      <th>length_behind_winner</th>\n",
       "      <th>...</th>\n",
       "      <th>running_position_6</th>\n",
       "      <th>race_id</th>\n",
       "      <th>recent_6_runs</th>\n",
       "      <th>recent_ave_rank</th>\n",
       "      <th>race_distance</th>\n",
       "      <th>HorseWin</th>\n",
       "      <th>HorseRankTop3</th>\n",
       "      <th>HorseRankTop50Percent</th>\n",
       "      <th>jockey_ave_rank</th>\n",
       "      <th>trainer_ave_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>DOUBLE DRAGON</td>\n",
       "      <td>K019</td>\n",
       "      <td>B Prebble</td>\n",
       "      <td>D Cruz</td>\n",
       "      <td>133</td>\n",
       "      <td>1032</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-001</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1400</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.052910</td>\n",
       "      <td>7.381862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>PLAIN BLUE BANNER</td>\n",
       "      <td>S070</td>\n",
       "      <td>D Whyte</td>\n",
       "      <td>D E Ferraris</td>\n",
       "      <td>133</td>\n",
       "      <td>1075</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-001</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1400</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.825153</td>\n",
       "      <td>6.611465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   finishing_position  horse_number         horse_name horse_id     jockey  \\\n",
       "0                   1           1.0      DOUBLE DRAGON     K019  B Prebble   \n",
       "1                   2           2.0  PLAIN BLUE BANNER     S070    D Whyte   \n",
       "\n",
       "        trainer  actual_weight  declared_horse_weight  draw  \\\n",
       "0        D Cruz            133                   1032     1   \n",
       "1  D E Ferraris            133                   1075    13   \n",
       "\n",
       "  length_behind_winner  ...  running_position_6   race_id  recent_6_runs  \\\n",
       "0                    -  ...                 NaN  2014-001              1   \n",
       "1                    2  ...                 NaN  2014-001              2   \n",
       "\n",
       "   recent_ave_rank race_distance  HorseWin  HorseRankTop3  \\\n",
       "0              1.0          1400         1              1   \n",
       "1              2.0          1400         0              1   \n",
       "\n",
       "   HorseRankTop50Percent jockey_ave_rank trainer_ave_rank  \n",
       "0                      1        6.052910         7.381862  \n",
       "1                      1        5.825153         6.611465  \n",
       "\n",
       "[2 rows x 27 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the first 2 rows of the train file\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>finishing_position</th>\n",
       "      <th>horse_number</th>\n",
       "      <th>horse_name</th>\n",
       "      <th>horse_id</th>\n",
       "      <th>jockey</th>\n",
       "      <th>trainer</th>\n",
       "      <th>actual_weight</th>\n",
       "      <th>declared_horse_weight</th>\n",
       "      <th>draw</th>\n",
       "      <th>length_behind_winner</th>\n",
       "      <th>...</th>\n",
       "      <th>running_position_6</th>\n",
       "      <th>race_id</th>\n",
       "      <th>recent_6_runs</th>\n",
       "      <th>recent_ave_rank</th>\n",
       "      <th>race_distance</th>\n",
       "      <th>HorseWin</th>\n",
       "      <th>HorseRankTop3</th>\n",
       "      <th>HorseRankTop50Percent</th>\n",
       "      <th>jockey_ave_rank</th>\n",
       "      <th>trainer_ave_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>POWERMAX</td>\n",
       "      <td>A009</td>\n",
       "      <td>N Callan</td>\n",
       "      <td>R Gibson</td>\n",
       "      <td>126</td>\n",
       "      <td>1124</td>\n",
       "      <td>9</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-328</td>\n",
       "      <td>1/4/3/3</td>\n",
       "      <td>2.7500</td>\n",
       "      <td>1200</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.438751</td>\n",
       "      <td>6.715420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>BUDDY BUNDY</td>\n",
       "      <td>T157</td>\n",
       "      <td>K K Chiong</td>\n",
       "      <td>D Cruz</td>\n",
       "      <td>127</td>\n",
       "      <td>1193</td>\n",
       "      <td>8</td>\n",
       "      <td>SH</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-328</td>\n",
       "      <td>2/11/5/2/6/9</td>\n",
       "      <td>6.8125</td>\n",
       "      <td>1200</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.499033</td>\n",
       "      <td>7.381862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   finishing_position  horse_number   horse_name horse_id      jockey  \\\n",
       "0                   1           5.0     POWERMAX     A009    N Callan   \n",
       "1                   2           2.0  BUDDY BUNDY     T157  K K Chiong   \n",
       "\n",
       "    trainer  actual_weight  declared_horse_weight  draw length_behind_winner  \\\n",
       "0  R Gibson            126                   1124     9                    -   \n",
       "1    D Cruz            127                   1193     8                   SH   \n",
       "\n",
       "   ...  running_position_6   race_id  recent_6_runs  recent_ave_rank  \\\n",
       "0  ...                 NaN  2016-328        1/4/3/3           2.7500   \n",
       "1  ...                 NaN  2016-328   2/11/5/2/6/9           6.8125   \n",
       "\n",
       "  race_distance  HorseWin  HorseRankTop3  HorseRankTop50Percent  \\\n",
       "0          1200         1              1                      1   \n",
       "1          1200         0              1                      1   \n",
       "\n",
       "  jockey_ave_rank trainer_ave_rank  \n",
       "0        6.438751         6.715420  \n",
       "1        6.499033         7.381862  \n",
       "\n",
       "[2 rows x 27 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the first 2 rows of the test files\n",
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing of Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[['actual_weight', 'declared_horse_weight',\n",
    "                    'draw', #'win_odds',\n",
    "                    'jockey_ave_rank','trainer_ave_rank',\n",
    "                    'recent_ave_rank','race_distance']]\n",
    "\n",
    "# Define the target\n",
    "y_train = df_train['finish_time']\n",
    "\n",
    "# Convert the target to seconds\n",
    "y_train = y_train.apply(lambda x: x.split('.'))\n",
    "y_train = y_train.apply(lambda x: int(x[0])*60 + int(x[1]) + int(x[2])/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    82.33\n",
       "1    82.65\n",
       "2    82.66\n",
       "3    82.66\n",
       "4    83.02\n",
       "Name: finish_time, dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the testing set\n",
    "X_test = df_test[['actual_weight', 'declared_horse_weight',\n",
    "                    'draw', #'win_odds', \n",
    "                    'jockey_ave_rank', 'trainer_ave_rank',\n",
    "                    'recent_ave_rank', 'race_distance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target\n",
    "y_test = df_test['finish_time']\n",
    "\n",
    "# Convert the target to seconds\n",
    "y_test = y_test.apply(lambda x: x.split('.'))\n",
    "y_test = y_test.apply(lambda x: int(x[0])*60 + int(x[1]) + int(x[2])/100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions to run and evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function finds the accuracy of the model for predicting the Top and Top 3 finishers\n",
    "def find_prob(y_pred):\n",
    "    \n",
    "    i=0\n",
    "    count_top_winners = 0\n",
    "    count_top_correct = 0\n",
    "\n",
    "    count_top3_winners = 0\n",
    "    count_top3_correct = 0\n",
    "\n",
    "    for column in ['HorseWin', 'HorseRankTop3']:\n",
    "            \n",
    "        for race in df_test['race_id'].unique():\n",
    "            \n",
    "            # Create temp dataframe\n",
    "            temp = df_test[df_test['race_id']==race]\n",
    "\n",
    "            # Get the index of the temp dataframe\n",
    "            temp_index = temp.index\n",
    "\n",
    "            # Find the index of the winners from the temp dataframe\n",
    "            if i == 0:\n",
    "                winners_index = temp[temp['finishing_position']==1].index\n",
    "            else:\n",
    "                winners_index = temp[temp['finishing_position']<=3].index\n",
    "\n",
    "            # Create a temp dataframe for the predicted probabilities\n",
    "            temp_pred = y_pred.iloc[temp_index]\n",
    "\n",
    "            # Sort the temp dataframe by the predicted timings\n",
    "            temp_pred = temp_pred.sort_values(by=temp_pred.columns[0])\n",
    "\n",
    "            # Get the index of the winners from the temp pred dataframe\n",
    "            if i == 0:\n",
    "                winners_pred_index = temp_pred[:1].index\n",
    "            else:\n",
    "                winners_pred_index = temp_pred[:3].index\n",
    "\n",
    "            # Count the number of winners and correct predictions\n",
    "            if i == 0:\n",
    "                count_top_winners += len(winners_index)\n",
    "                count_top_correct += len(set(winners_index).intersection(set(winners_pred_index)))\n",
    "            else:\n",
    "                count_top3_winners += len(winners_index)\n",
    "                count_top3_correct += len(set(winners_index).intersection(set(winners_pred_index)))\n",
    "        i+=1\n",
    "    \n",
    "    # Calculate the accuracy\n",
    "    top_accuracy = round(count_top_correct/count_top_winners, 3)\n",
    "    top3_accuracy = round(count_top3_correct/count_top3_winners, 3)\n",
    "\n",
    "    return top_accuracy, top3_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe to store the results\n",
    "results = pd.DataFrame(columns=['Model', 'RMSE_train', 'RMSE_test', \n",
    "                                'Generalization', 'Top1_Train_Accuracy', 'Top1_Test_Accuracy',\n",
    "                                'Top3_Train_Accuracy', 'Top3_Test_Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to run the model\n",
    "def run_model(model, X_train, y_train, X_test, y_test):\n",
    "\n",
    "        # Store model name\n",
    "        model_name = model.__class__.__name__\n",
    "\n",
    "        # Scale the data\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        # Fit the model         \n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict on the training set\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_train_pred = pd.DataFrame(y_train_pred)\n",
    "\n",
    "        # Predict on the testing set\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        y_test_pred = pd.DataFrame(y_test_pred)\n",
    "\n",
    "        # Calculate the RMSE\n",
    "        train_rmse = round(math.sqrt(mean_squared_error(y_train, y_train_pred)), 3)\n",
    "        test_rmse = round(math.sqrt(mean_squared_error(y_test, y_test_pred)), 3)\n",
    "        \n",
    "        # Calculate the accuracy\n",
    "        train_accuracy, train_accuracy_top3 = find_prob(y_train_pred)\n",
    "        test_accuracy, test_accuracy_top3 = find_prob(y_test_pred)\n",
    "\n",
    "        # Calculate generalization error percentage\n",
    "        generalization_error = round((test_rmse - train_rmse)/train_rmse*100, 3)\n",
    "\n",
    "        # Print the results\n",
    "        print('Model results for', model_name, ':')\n",
    "        print('Train RMSE: ', train_rmse)\n",
    "        print('Test RMSE: ', test_rmse)\n",
    "        print('Generalization Error: ', generalization_error, '%', '\\n')\n",
    "\n",
    "        print('Train Accuracy for finding Top position: ', train_accuracy)\n",
    "        print('Test Accuracy for finding Top position: ', test_accuracy, '\\n')\n",
    "\n",
    "        print('Train Accuracy for finding Top 3 positions: ', train_accuracy_top3)\n",
    "        print('Test Accuracy for finding Top 3 positions: ', test_accuracy_top3)\n",
    "\n",
    "        # Append the results to the dataframe\n",
    "        results.loc[len(results)] = [model_name, train_rmse, test_rmse, generalization_error,\n",
    "                                  train_accuracy, test_accuracy, train_accuracy_top3, test_accuracy_top3]\n",
    "        \n",
    "        return y_test_pred\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model\n",
    "ridge = Ridge(alpha=2600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for Ridge :\n",
      "Train RMSE:  2.283\n",
      "Test RMSE:  2.393\n",
      "Generalization Error:  4.818 % \n",
      "\n",
      "Train Accuracy for finding Top position:  0.184\n",
      "Test Accuracy for finding Top position:  0.23 \n",
      "\n",
      "Train Accuracy for finding Top 3 positions:  0.371\n",
      "Test Accuracy for finding Top 3 positions:  0.392\n"
     ]
    }
   ],
   "source": [
    "# Run the model\n",
    "ridge_pred = run_model(ridge, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: K-Nearest Neighbors Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for KNeighborsRegressor :\n",
      "Train RMSE:  4.048\n",
      "Test RMSE:  4.168\n",
      "Generalization Error:  2.964 % \n",
      "\n",
      "Train Accuracy for finding Top position:  0.142\n",
      "Test Accuracy for finding Top position:  0.167 \n",
      "\n",
      "Train Accuracy for finding Top 3 positions:  0.299\n",
      "Test Accuracy for finding Top 3 positions:  0.31\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "knn = KNeighborsRegressor(n_neighbors=50)\n",
    "\n",
    "knn_pred = run_model(knn, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for RandomForestRegressor :\n",
      "Train RMSE:  2.42\n",
      "Test RMSE:  2.563\n",
      "Generalization Error:  5.909 % \n",
      "\n",
      "Train Accuracy for finding Top position:  0.169\n",
      "Test Accuracy for finding Top position:  0.18 \n",
      "\n",
      "Train Accuracy for finding Top 3 positions:  0.374\n",
      "Test Accuracy for finding Top 3 positions:  0.382\n"
     ]
    }
   ],
   "source": [
    "# Run the model\n",
    "rf = RandomForestRegressor(n_estimators=30, max_depth=4, random_state=42, max_features=5,\n",
    "                            min_samples_split=20, min_samples_leaf=250, n_jobs=-1)\n",
    "\n",
    "rf_pred = run_model(rf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: Light Gradient Boosting Machine (LightGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for LGBMRegressor :\n",
      "Train RMSE:  2.526\n",
      "Test RMSE:  2.649\n",
      "Generalization Error:  4.869 % \n",
      "\n",
      "Train Accuracy for finding Top position:  0.226\n",
      "Test Accuracy for finding Top position:  0.316 \n",
      "\n",
      "Train Accuracy for finding Top 3 positions:  0.416\n",
      "Test Accuracy for finding Top 3 positions:  0.485\n"
     ]
    }
   ],
   "source": [
    "# Run the model\n",
    "lgbm = LGBMRegressor(n_estimators=20, max_depth=5, random_state=42, num_leaves=100,\n",
    "                     min_child_samples=10, min_child_weight=10, n_jobs=-1)\n",
    "\n",
    "lgbm_pred = run_model(lgbm, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View results of our 4 regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>Generalization</th>\n",
       "      <th>Top1_Train_Accuracy</th>\n",
       "      <th>Top1_Test_Accuracy</th>\n",
       "      <th>Top3_Train_Accuracy</th>\n",
       "      <th>Top3_Test_Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>2.283</td>\n",
       "      <td>2.393</td>\n",
       "      <td>4.818</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>4.048</td>\n",
       "      <td>4.168</td>\n",
       "      <td>2.964</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>2.420</td>\n",
       "      <td>2.563</td>\n",
       "      <td>5.909</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>2.526</td>\n",
       "      <td>2.649</td>\n",
       "      <td>4.869</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model  RMSE_train  RMSE_test  Generalization  \\\n",
       "0                  Ridge       2.283      2.393           4.818   \n",
       "1    KNeighborsRegressor       4.048      4.168           2.964   \n",
       "2  RandomForestRegressor       2.420      2.563           5.909   \n",
       "3          LGBMRegressor       2.526      2.649           4.869   \n",
       "\n",
       "   Top1_Train_Accuracy  Top1_Test_Accuracy  Top3_Train_Accuracy  \\\n",
       "0                0.184               0.230                0.371   \n",
       "1                0.142               0.167                0.299   \n",
       "2                0.169               0.180                0.374   \n",
       "3                0.226               0.316                0.416   \n",
       "\n",
       "   Top3_Test_Accuracy  \n",
       "0               0.392  \n",
       "1               0.310  \n",
       "2               0.382  \n",
       "3               0.485  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the results\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our objective is to have low RMSE, good generalisation, and good training accuracy, the LGBMRegressor meets all the criteria and we will choose it as our final model for backtesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "ridge_pred.to_csv('./predictions/ridge_pred.csv')\n",
    "knn_pred.to_csv('./predictions/knn_pred.csv')\n",
    "rf_pred.to_csv('./predictions/rf_pred.csv')\n",
    "lgbm_pred.to_csv('./predictions/lgbm_pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./model/lgbm_model.pkl']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "joblib.dump(lgbm, './model/lgbm_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results\n",
    "results.to_csv('./results/reg_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "fc902f5f9f1b4ac8244fa2d1a71d10e1bb8b95bd909217946ac119cb82bcf206"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
