{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Horse Racing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gambling on the horse racing results is a breathtaking entertainment. The results of horse races don’t come from nowhere. They are related to different factors such as the horses and jockeys, the track and distance, etc. We wonder whether we can “predict” the results of horse races and build our “formula” to win the rewards. In this project, we will use data from past races and try different machine learning techniques to make predictions.\n",
    "\n",
    "The dataset is from kaggle (www.kaggle.com/lantanacamara/hong-kong-horse-racing) which is extracted from the website of the Hong Kongm Jockey Club. The file race-result-race.csv describes the races. Each entry in another file race-result-horse.csv corresponds to one horse in a race."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # II.  Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Description: \n",
    "• finishing_position: the rank of the horse. (E.g. the horse with finishing_position 1 is the first to finish)\n",
    "\n",
    "• horse_number: the number for the horse in the specific race. (Note that the same horse may have different numbers in different races)\n",
    "\n",
    "• horse_name: English name of the horse.\n",
    "\n",
    "• horse_id: ID of the horse. (The ID for a horse is unique in all the races)\n",
    "\n",
    "• jockey: the one who rides the horse in the race. (A jockey can ride different horses in the races)\n",
    "\n",
    "• trainer: the one who trains the horse. (Multiple horses from a trainer can appear in the same race)\n",
    "\n",
    "• actual_weight: the extra weight that the horse carries in the race. (The horses with better perfor- mances in the previous races should carry heavier extra weights, to make the race more competitive6)\n",
    "\n",
    "• declared_horse_weight: the weight of the horse on date of the race.\n",
    "\n",
    "• draw: the position of the horse at the starting point7. The inner positions are usually advantageous and correspond to smaller draw numbers.\n",
    "\n",
    "• length_behind_winner: the length behind the winner at the finish line. The unit is the “horse length”.\n",
    "\n",
    "• running_position_1: the rank of the horse at the first timing point.\n",
    "\n",
    "• running_position_2: the rank of the horse at the second timing point.\n",
    "...\n",
    "\n",
    "• running_position_i: the rank of the horse at the ith timing point. (The running position will be “NA” if the total distance of the race is short and the horses don’t go across the particular timing point)\n",
    "\n",
    "• finish_time: the total time from the starting point to the finish line. The unit is “second”.\n",
    "\n",
    "• win_odds: the ratio between the reward you will get and the money you bet, supposing that you will win. The odds are usually determined automatically by the total money bet on each horses8. \n",
    "\n",
    "• race_id: the ID of the race for this entry. The race_id is consistent in the two data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30189, 19)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horse = pd.read_csv('./data/race-result-horse.csv')\n",
    "horse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30189 entries, 0 to 30188\n",
      "Data columns (total 19 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   finishing_position     30187 non-null  object \n",
      " 1   horse_number           29851 non-null  float64\n",
      " 2   horse_name             30189 non-null  object \n",
      " 3   horse_id               30189 non-null  object \n",
      " 4   jockey                 30189 non-null  object \n",
      " 5   trainer                30189 non-null  object \n",
      " 6   actual_weight          30189 non-null  object \n",
      " 7   declared_horse_weight  30189 non-null  object \n",
      " 8   draw                   30189 non-null  object \n",
      " 9   length_behind_winner   30189 non-null  object \n",
      " 10  running_position_1     29574 non-null  float64\n",
      " 11  running_position_2     29560 non-null  float64\n",
      " 12  running_position_3     29542 non-null  float64\n",
      " 13  running_position_4     16618 non-null  float64\n",
      " 14  finish_time            30189 non-null  object \n",
      " 15  win_odds               30189 non-null  object \n",
      " 16  running_position_5     3764 non-null   float64\n",
      " 17  running_position_6     549 non-null    float64\n",
      " 18  race_id                30189 non-null  object \n",
      "dtypes: float64(7), object(12)\n",
      "memory usage: 4.4+ MB\n"
     ]
    }
   ],
   "source": [
    "horse.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>finishing_position</th>\n",
       "      <th>horse_number</th>\n",
       "      <th>horse_name</th>\n",
       "      <th>horse_id</th>\n",
       "      <th>jockey</th>\n",
       "      <th>trainer</th>\n",
       "      <th>actual_weight</th>\n",
       "      <th>declared_horse_weight</th>\n",
       "      <th>draw</th>\n",
       "      <th>length_behind_winner</th>\n",
       "      <th>running_position_1</th>\n",
       "      <th>running_position_2</th>\n",
       "      <th>running_position_3</th>\n",
       "      <th>running_position_4</th>\n",
       "      <th>finish_time</th>\n",
       "      <th>win_odds</th>\n",
       "      <th>running_position_5</th>\n",
       "      <th>running_position_6</th>\n",
       "      <th>race_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>DOUBLE DRAGON</td>\n",
       "      <td>K019</td>\n",
       "      <td>B Prebble</td>\n",
       "      <td>D Cruz</td>\n",
       "      <td>133</td>\n",
       "      <td>1032</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.22.33</td>\n",
       "      <td>3.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>PLAIN BLUE BANNER</td>\n",
       "      <td>S070</td>\n",
       "      <td>D Whyte</td>\n",
       "      <td>D E Ferraris</td>\n",
       "      <td>133</td>\n",
       "      <td>1075</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.22.65</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>GOLDWEAVER</td>\n",
       "      <td>P072</td>\n",
       "      <td>Y T Cheng</td>\n",
       "      <td>Y S Tsui</td>\n",
       "      <td>121</td>\n",
       "      <td>1065</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.22.66</td>\n",
       "      <td>5.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>SUPREME PROFIT</td>\n",
       "      <td>P230</td>\n",
       "      <td>J Moreira</td>\n",
       "      <td>C S Shum</td>\n",
       "      <td>132</td>\n",
       "      <td>1222</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.22.66</td>\n",
       "      <td>6.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>THE ONLY KID</td>\n",
       "      <td>H173</td>\n",
       "      <td>Z Purton</td>\n",
       "      <td>K W Lui</td>\n",
       "      <td>125</td>\n",
       "      <td>1136</td>\n",
       "      <td>9</td>\n",
       "      <td>4-1/4</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.23.02</td>\n",
       "      <td>6.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index finishing_position  horse_number         horse_name horse_id  \\\n",
       "0      0                  1           1.0      DOUBLE DRAGON     K019   \n",
       "1      1                  2           2.0  PLAIN BLUE BANNER     S070   \n",
       "2      2                  3          10.0         GOLDWEAVER     P072   \n",
       "3      3                  4           3.0     SUPREME PROFIT     P230   \n",
       "4      4                  5           7.0       THE ONLY KID     H173   \n",
       "\n",
       "      jockey       trainer actual_weight declared_horse_weight draw  \\\n",
       "0  B Prebble        D Cruz           133                  1032    1   \n",
       "1    D Whyte  D E Ferraris           133                  1075   13   \n",
       "2  Y T Cheng      Y S Tsui           121                  1065    3   \n",
       "3  J Moreira      C S Shum           132                  1222    2   \n",
       "4   Z Purton       K W Lui           125                  1136    9   \n",
       "\n",
       "  length_behind_winner  running_position_1  running_position_2  \\\n",
       "0                    -                 1.0                 2.0   \n",
       "1                    2                 8.0                 9.0   \n",
       "2                    2                 2.0                 1.0   \n",
       "3                    2                 6.0                 4.0   \n",
       "4                4-1/4                 9.0                10.0   \n",
       "\n",
       "   running_position_3  running_position_4 finish_time win_odds  \\\n",
       "0                 2.0                 1.0     1.22.33      3.8   \n",
       "1                 9.0                 2.0     1.22.65        8   \n",
       "2                 1.0                 3.0     1.22.66      5.7   \n",
       "3                 5.0                 4.0     1.22.66      6.1   \n",
       "4                10.0                 5.0     1.23.02      6.1   \n",
       "\n",
       "   running_position_5  running_position_6   race_id  \n",
       "0                 NaN                 NaN  2014-001  \n",
       "1                 NaN                 NaN  2014-001  \n",
       "2                 NaN                 NaN  2014-001  \n",
       "3                 NaN                 NaN  2014-001  \n",
       "4                 NaN                 NaN  2014-001  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  drop the rows where the “finish_position” is not a number (e.g. WV-A, WV). There may be accidents.\n",
    "rrh = rrh[rrh.finishing_position.isin(['1','2','3','4','5','6','7','8','9','10','11','12','13','14'])].reset_index()\n",
    "rrh.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of horses:  2155 \n",
      " Number of Jokeys:  105 \n",
      " Number of Trainers:  93\n"
     ]
    }
   ],
   "source": [
    "horse_id = rrh.horse_id.unique()\n",
    "no_horse = len(horse_id)\n",
    "horse_index = range(no_horse)\n",
    "\n",
    "jockey = rrh.jockey.unique()\n",
    "no_jockey = len(jockey)\n",
    "jockey_index = range(no_jockey)\n",
    "\n",
    "trainer = rrh.trainer.unique()\n",
    "no_trainer = len(trainer)\n",
    "trainer_index = range(no_trainer)\n",
    "\n",
    "print(' Number of horses: ' , no_horse , '\\n', 'Number of Jokeys: ' , no_jockey ,'\\n', 'Number of Trainers: ' , no_trainer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>finishing_position</th>\n",
       "      <th>horse_number</th>\n",
       "      <th>horse_name</th>\n",
       "      <th>horse_id</th>\n",
       "      <th>jockey</th>\n",
       "      <th>trainer</th>\n",
       "      <th>actual_weight</th>\n",
       "      <th>declared_horse_weight</th>\n",
       "      <th>draw</th>\n",
       "      <th>length_behind_winner</th>\n",
       "      <th>running_position_1</th>\n",
       "      <th>running_position_2</th>\n",
       "      <th>running_position_3</th>\n",
       "      <th>running_position_4</th>\n",
       "      <th>finish_time</th>\n",
       "      <th>win_odds</th>\n",
       "      <th>running_position_5</th>\n",
       "      <th>running_position_6</th>\n",
       "      <th>race_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>DOUBLE DRAGON</td>\n",
       "      <td>K019</td>\n",
       "      <td>B Prebble</td>\n",
       "      <td>D Cruz</td>\n",
       "      <td>133</td>\n",
       "      <td>1032</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.22.33</td>\n",
       "      <td>3.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>PLAIN BLUE BANNER</td>\n",
       "      <td>S070</td>\n",
       "      <td>D Whyte</td>\n",
       "      <td>D E Ferraris</td>\n",
       "      <td>133</td>\n",
       "      <td>1075</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.22.65</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>GOLDWEAVER</td>\n",
       "      <td>P072</td>\n",
       "      <td>Y T Cheng</td>\n",
       "      <td>Y S Tsui</td>\n",
       "      <td>121</td>\n",
       "      <td>1065</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.22.66</td>\n",
       "      <td>5.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>SUPREME PROFIT</td>\n",
       "      <td>P230</td>\n",
       "      <td>J Moreira</td>\n",
       "      <td>C S Shum</td>\n",
       "      <td>132</td>\n",
       "      <td>1222</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.22.66</td>\n",
       "      <td>6.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>THE ONLY KID</td>\n",
       "      <td>H173</td>\n",
       "      <td>Z Purton</td>\n",
       "      <td>K W Lui</td>\n",
       "      <td>125</td>\n",
       "      <td>1136</td>\n",
       "      <td>9</td>\n",
       "      <td>4-1/4</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.23.02</td>\n",
       "      <td>6.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index finishing_position  horse_number         horse_name horse_id  \\\n",
       "0      0                  1           1.0      DOUBLE DRAGON     K019   \n",
       "1      1                  2           2.0  PLAIN BLUE BANNER     S070   \n",
       "2      2                  3          10.0         GOLDWEAVER     P072   \n",
       "3      3                  4           3.0     SUPREME PROFIT     P230   \n",
       "4      4                  5           7.0       THE ONLY KID     H173   \n",
       "\n",
       "      jockey       trainer actual_weight declared_horse_weight draw  \\\n",
       "0  B Prebble        D Cruz           133                  1032    1   \n",
       "1    D Whyte  D E Ferraris           133                  1075   13   \n",
       "2  Y T Cheng      Y S Tsui           121                  1065    3   \n",
       "3  J Moreira      C S Shum           132                  1222    2   \n",
       "4   Z Purton       K W Lui           125                  1136    9   \n",
       "\n",
       "  length_behind_winner  running_position_1  running_position_2  \\\n",
       "0                    -                 1.0                 2.0   \n",
       "1                    2                 8.0                 9.0   \n",
       "2                    2                 2.0                 1.0   \n",
       "3                    2                 6.0                 4.0   \n",
       "4                4-1/4                 9.0                10.0   \n",
       "\n",
       "   running_position_3  running_position_4 finish_time win_odds  \\\n",
       "0                 2.0                 1.0     1.22.33      3.8   \n",
       "1                 9.0                 2.0     1.22.65        8   \n",
       "2                 1.0                 3.0     1.22.66      5.7   \n",
       "3                 5.0                 4.0     1.22.66      6.1   \n",
       "4                10.0                 5.0     1.23.02      6.1   \n",
       "\n",
       "   running_position_5  running_position_6   race_id  \n",
       "0                 NaN                 NaN  2014-001  \n",
       "1                 NaN                 NaN  2014-001  \n",
       "2                 NaN                 NaN  2014-001  \n",
       "3                 NaN                 NaN  2014-001  \n",
       "4                 NaN                 NaN  2014-001  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rrh.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Takes a while to run\n",
    "\n",
    "# Add a column named recent_6_runs to the dataframe, which records the recent ranks of the horse in each entry. \n",
    "# The ranks are separated by “/”, and a record is like 1/2/6/3/4/7.\n",
    "\n",
    "# Add a column named recent_ave_rank for each entry to the dataframe, \n",
    "# which records the average rank of the recent 6 runs of a horse\n",
    "\n",
    "rrh['recent_6_runs'] = '0'\n",
    "rrh['recent_ave_rank'] = '7'\n",
    "\n",
    "for i in range(len(rrh['finishing_position'])):\n",
    "    \n",
    "    temp = rrh[ : (i + 1)][rrh.horse_id == rrh.horse_id[i]][['finishing_position']]\n",
    "    temp = temp['finishing_position'].values.tolist()[::-1]\n",
    "  \n",
    "    rrh['recent_6_runs'][i] = '/'.join(temp[:6])\n",
    "    \n",
    "    if len(temp) != 0:\n",
    "        temp_int = map(int,temp)    # convert string to integer\n",
    "        temp_ave = np.mean(list(temp_int))\n",
    "        rrh['recent_ave_rank'][i] = temp_ave\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>finishing_position</th>\n",
       "      <th>horse_number</th>\n",
       "      <th>horse_name</th>\n",
       "      <th>horse_id</th>\n",
       "      <th>jockey</th>\n",
       "      <th>trainer</th>\n",
       "      <th>actual_weight</th>\n",
       "      <th>declared_horse_weight</th>\n",
       "      <th>draw</th>\n",
       "      <th>...</th>\n",
       "      <th>running_position_2</th>\n",
       "      <th>running_position_3</th>\n",
       "      <th>running_position_4</th>\n",
       "      <th>finish_time</th>\n",
       "      <th>win_odds</th>\n",
       "      <th>running_position_5</th>\n",
       "      <th>running_position_6</th>\n",
       "      <th>race_id</th>\n",
       "      <th>recent_6_runs</th>\n",
       "      <th>recent_ave_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>DOUBLE DRAGON</td>\n",
       "      <td>K019</td>\n",
       "      <td>B Prebble</td>\n",
       "      <td>D Cruz</td>\n",
       "      <td>133</td>\n",
       "      <td>1032</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.22.33</td>\n",
       "      <td>3.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-001</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>PLAIN BLUE BANNER</td>\n",
       "      <td>S070</td>\n",
       "      <td>D Whyte</td>\n",
       "      <td>D E Ferraris</td>\n",
       "      <td>133</td>\n",
       "      <td>1075</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.22.65</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-001</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>GOLDWEAVER</td>\n",
       "      <td>P072</td>\n",
       "      <td>Y T Cheng</td>\n",
       "      <td>Y S Tsui</td>\n",
       "      <td>121</td>\n",
       "      <td>1065</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.22.66</td>\n",
       "      <td>5.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-001</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>SUPREME PROFIT</td>\n",
       "      <td>P230</td>\n",
       "      <td>J Moreira</td>\n",
       "      <td>C S Shum</td>\n",
       "      <td>132</td>\n",
       "      <td>1222</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.22.66</td>\n",
       "      <td>6.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-001</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>THE ONLY KID</td>\n",
       "      <td>H173</td>\n",
       "      <td>Z Purton</td>\n",
       "      <td>K W Lui</td>\n",
       "      <td>125</td>\n",
       "      <td>1136</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.23.02</td>\n",
       "      <td>6.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-001</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index finishing_position  horse_number         horse_name horse_id  \\\n",
       "0      0                  1           1.0      DOUBLE DRAGON     K019   \n",
       "1      1                  2           2.0  PLAIN BLUE BANNER     S070   \n",
       "2      2                  3          10.0         GOLDWEAVER     P072   \n",
       "3      3                  4           3.0     SUPREME PROFIT     P230   \n",
       "4      4                  5           7.0       THE ONLY KID     H173   \n",
       "\n",
       "      jockey       trainer actual_weight declared_horse_weight draw  ...  \\\n",
       "0  B Prebble        D Cruz           133                  1032    1  ...   \n",
       "1    D Whyte  D E Ferraris           133                  1075   13  ...   \n",
       "2  Y T Cheng      Y S Tsui           121                  1065    3  ...   \n",
       "3  J Moreira      C S Shum           132                  1222    2  ...   \n",
       "4   Z Purton       K W Lui           125                  1136    9  ...   \n",
       "\n",
       "  running_position_2  running_position_3  running_position_4  finish_time  \\\n",
       "0                2.0                 2.0                 1.0      1.22.33   \n",
       "1                9.0                 9.0                 2.0      1.22.65   \n",
       "2                1.0                 1.0                 3.0      1.22.66   \n",
       "3                4.0                 5.0                 4.0      1.22.66   \n",
       "4               10.0                10.0                 5.0      1.23.02   \n",
       "\n",
       "   win_odds running_position_5 running_position_6   race_id  recent_6_runs  \\\n",
       "0       3.8                NaN                NaN  2014-001              1   \n",
       "1         8                NaN                NaN  2014-001              2   \n",
       "2       5.7                NaN                NaN  2014-001              3   \n",
       "3       6.1                NaN                NaN  2014-001              4   \n",
       "4       6.1                NaN                NaN  2014-001              5   \n",
       "\n",
       "  recent_ave_rank  \n",
       "0             1.0  \n",
       "1             2.0  \n",
       "2             3.0  \n",
       "3             4.0  \n",
       "4             5.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rrh.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Add column of Distance\n",
    "\n",
    "# The distance could be 1000, 1200, 1400, 1600, 1800, 2000, 2400, etc. \n",
    "# Some horses are good at short-distance races, while some are good at long-distance races.\n",
    "\n",
    "rrh['race_distance'] = '0'\n",
    "rrr = pd.read_csv('./data/race-result-race.csv')\n",
    "for i in range(len(rrr['race_id'])):\n",
    "    distance = rrr['race_distance'][i]\n",
    "    rrh['race_distance'][rrh.race_id == rrr.race_id[i]] = distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add HorseWin, HorseRankTop3, HorseRankTop50Percent for use in Part3\n",
    "\n",
    "rrh['HorseWin'] = (rrh.finishing_position == '1') + 0\n",
    "rrh['HorseRankTop3'] = (rrh.finishing_position == '1') + (rrh.finishing_position == '2') + (rrh.finishing_position == '3') + 0\n",
    "\n",
    "index=rrh.index[rrh['finishing_position'] == '1'].tolist()\n",
    "\n",
    "rrh['HorseRankTop50Percent'] = '0'\n",
    "for i in range(len(index)-1):\n",
    "    rrh['HorseRankTop50Percent'][index[i]:(index[i] + int(round(0.5 * (index[i + 1] - index[i]))))] = '1'\n",
    "rrh['HorseRankTop50Percent'][index[len(index) - 1]:(index[len(index) - 1] + 6)] = '1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide data into training set and test set.\n",
    "# Training set contains all the races with race_id no more than “2016-327” (first 80%), \n",
    "# Test set contains the rest of races (last 20%)\n",
    "\n",
    "temp_index = max(rrh.index[rrh['race_id'] == '2016-327'].tolist())\n",
    "training = rrh[:(temp_index + 1)]\n",
    "testing = rrh[(temp_index + 1):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate jockey_ave_rank, trainer_ave_rank for training data\n",
    "# jockey_ave_rank: records the average rank of the jockey in the training data\n",
    "# trainer_ave_rank:records the average rank of the trainer in the training data\n",
    "\n",
    "\n",
    "training['jockey_ave_rank'] = '7'\n",
    "\n",
    "for i in range(len(jockey)):\n",
    "    temp = training[training.jockey == jockey[i]][['finishing_position']]\n",
    "    temp = temp['finishing_position'].values.tolist()\n",
    "    if len(temp) != 0:\n",
    "        temp_int = map(int,temp)\n",
    "        temp_ave = np.mean(list(temp_int))\n",
    "        training['jockey_ave_rank'][training.jockey == jockey[i]] = temp_ave\n",
    "\n",
    "\n",
    "training['trainer_ave_rank'] = '7'\n",
    "\n",
    "for i in range(len(trainer)):\n",
    "    temp = training[training.trainer == trainer[i]][['finishing_position']]\n",
    "    temp = temp['finishing_position'].values.tolist()\n",
    "    if len(temp) != 0:\n",
    "        temp_int = map(int,temp)\n",
    "        temp_ave = np.mean(list(temp_int))\n",
    "        training['trainer_ave_rank'][training.trainer == trainer[i]] = temp_ave\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.to_csv('training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "####----Refer jockey_ave_rank and trainer_ave_rank of testing data to training data---####\n",
    "\n",
    "testing['jockey_ave_rank'] = '7'\n",
    "testing_jockey = testing['jockey'].unique()\n",
    "for i in range(len(testing_jockey)):\n",
    "    if testing_jockey[i] in training['jockey'].unique():\n",
    "        testing['jockey_ave_rank'][testing.jockey == testing_jockey[i]] = training[training.jockey == testing_jockey[i]]['jockey_ave_rank'].tolist()[0]\n",
    "\n",
    "testing['trainer_ave_rank'] = '7'\n",
    "testing_trainer=testing['trainer'].unique()\n",
    "for i in range(len(testing_trainer)):\n",
    "    if testing_trainer[i] in training['trainer'].unique():\n",
    "        testing['trainer_ave_rank'][testing.trainer == testing_trainer[i]] = training[training.trainer == testing_trainer[i]]['trainer_ave_rank'].tolist()[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing.to_csv('testing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III.  Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv('training.csv')\n",
    "testing = pd.read_csv('testing.csv')\n",
    "X_train = training[['actual_weight','declared_horse_weight','draw','win_odds','jockey_ave_rank','trainer_ave_rank',\n",
    "'recent_ave_rank','race_distance']]\n",
    "y_train = training[['HorseWin','HorseRankTop3','HorseRankTop50Percent']]\n",
    "X_test = testing[['actual_weight','declared_horse_weight','draw','win_odds','jockey_ave_rank','trainer_ave_rank',\n",
    "'recent_ave_rank','race_distance']]\n",
    "y_test = testing[['HorseWin','HorseRankTop3','HorseRankTop50Percent']]\n",
    "\n",
    "kfold = KFold(n_splits = 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation\n",
    "Cross validation can estimate the expected extra-sample error. Since static split of training and testing data cannot build a very good model given out-of-sample data, CV efficiently utilizes the data and also improves performance in predicting out-of-sample data, thus avoiding overfitting problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation score for Logistic Regression: \n",
      " HorseWin:  [0.05128205 0.05684755 0.03626943 0.03626943 0.04639175] \n",
      " HorseTop3:  [0.62089259 0.42474717 0.43452022 0.39785587 0.35264798] \n",
      " HorseTop50Percent:  [0.79868394 0.72073965 0.70459247 0.69849041 0.68211649]\n"
     ]
    }
   ],
   "source": [
    "score_lr_Win = cross_val_score(lr_model,X_train,y_train['HorseWin'],cv = kfold,scoring = 'f1')\n",
    "score_lr_Top3 = cross_val_score(lr_model,X_train,y_train['HorseRankTop3'],cv = kfold,scoring = 'f1')\n",
    "score_lr_Top50 = cross_val_score(lr_model,X_train,y_train['HorseRankTop50Percent'],cv = kfold,scoring = 'f1')\n",
    "print(\"Cross Validation score for Logistic Regression:\",'\\n', \"HorseWin: \",score_lr_Win,'\\n',\"HorseTop3: \", \n",
    "      score_lr_Top3,'\\n',\"HorseTop50Percent: \", score_lr_Top50 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Predictions \n",
    "\n",
    "HorseWin: If the horse was in the first finish speeds, ‘1’ else ‘0’.\n",
    "\n",
    "HorseRankTop3: If the horse was in the top 3 finish speeds, ‘1’ else ‘0’.\n",
    "\n",
    "HorseRankTop50Percent: If the horse was in the top 50 percent finish speeds, ’1’ else ‘0’.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time for logistic rergession is:  0.3040473461151123\n"
     ]
    }
   ],
   "source": [
    "start_time1 = time.time()\n",
    "lr_model.fit(X_train,y_train['HorseWin'])\n",
    "lr_Win = lr_model.predict(X_test)\n",
    "lr_model.fit(X_train,y_train['HorseRankTop3'])\n",
    "lr_Top3 = lr_model.predict(X_test)\n",
    "lr_model.fit(X_train,y_train['HorseRankTop50Percent'])\n",
    "lr_Top50 = lr_model.predict(X_test)\n",
    "print('Running time for logistic rergession is: ' , time.time() - start_time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write predictions into csv file.\n",
    "a = pd.DataFrame()\n",
    "a['RaceID'] = testing['race_id']\n",
    "a['HorseID'] = testing['horse_id']\n",
    "a['HorseWin'] = lr_Win\n",
    "a['HorseRankTop3'] = lr_Top3\n",
    "a['HorseRankTop50Percent'] = lr_Top50\n",
    "a.to_csv('lr_predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of Predictions _ F1 score\n",
    "\n",
    "Reasons of choosing F1: For imbalanced data, 1 is more important than 0, model may try to increase accuracy by predicting all 0, while in this case, f1 score is close to 0 while accuracy is close to 1. So for imbalanced data, f1 score (similarly TNR, NPV) is good choice.\n",
    "\n",
    "F1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "Precision P = TP / (TP + FP), probability that one classified positive instance is classified correctly.\n",
    "\n",
    "Recall R = TP / (TP +FN) , percentage of truly positive instances correctly classified. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " F1 score of HorseWin:  0.0529531568228106 \n",
      " F1 score of HorseRankTop3:  0.3595617529880478 \n",
      " F1 score of HorseRankTop50Percent:  0.693624653513778\n"
     ]
    }
   ],
   "source": [
    "print(' F1 score of HorseWin: ' , f1_score(y_test['HorseWin'],a['HorseWin']),'\\n', 'F1 score of HorseRankTop3: ',\n",
    "      f1_score(y_test['HorseRankTop3'],a['HorseRankTop3']),'\\n', 'F1 score of HorseRankTop50Percent: ',\n",
    "      f1_score(y_test['HorseRankTop50Percent'],a['HorseRankTop50Percent']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Naïve Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised learning algorithms based on applying Bayes’ theorem with the “naive” assumption of independence between every pair of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation score for Naive Bayes:  \n",
      " HorseWin:  [0.36181818 0.34763476 0.31038251 0.28542304 0.28210526] \n",
      " HorseTop3:  [0.61533173 0.53181818 0.53748126 0.51724138 0.51145602] \n",
      " HorseTop50Percent:  [0.7785575  0.72748447 0.7187017  0.71444738 0.71051152]\n"
     ]
    }
   ],
   "source": [
    "score_nb_Win=cross_val_score(nb_model,X_train,y_train['HorseWin'],cv=kfold,scoring='f1')\n",
    "score_nb_Top3=cross_val_score(nb_model,X_train,y_train['HorseRankTop3'],cv=kfold,scoring='f1')\n",
    "score_nb_Top50=cross_val_score(nb_model,X_train,y_train['HorseRankTop50Percent'],cv=kfold,scoring='f1')\n",
    "print(\"Cross Validation score for Naive Bayes: \",'\\n', \"HorseWin: \",score_nb_Win,'\\n',\"HorseTop3: \", \n",
    "      score_nb_Top3,'\\n',\"HorseTop50Percent: \", score_nb_Top50 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time for Naive Bayes in scikit-learn is:  0.024024248123168945\n"
     ]
    }
   ],
   "source": [
    "start_time2 = time.time()\n",
    "nb_model.fit(X_train,y_train['HorseWin'])\n",
    "nb_Win = nb_model.predict(X_test)\n",
    "nb_model.fit(X_train,y_train['HorseRankTop3'])\n",
    "nb_Top3 = nb_model.predict(X_test)\n",
    "nb_model.fit(X_train,y_train['HorseRankTop50Percent'])\n",
    "nb_Top50 = nb_model.predict(X_test)\n",
    "print('Running time for Naive Bayes in scikit-learn is: ' , time.time()-start_time2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.DataFrame()\n",
    "b['RaceID'] = testing['race_id']\n",
    "b['HorseID'] = testing['horse_id']\n",
    "b['HorseWin'] = nb_Win\n",
    "b['HorseRankTop3'] = nb_Top3\n",
    "b['HorseRankTop50Percent'] = nb_Top50\n",
    "b.to_csv('nb_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " F1 score of HorseWin:  0.2820945945945946 \n",
      " F1 score of HorseRankTop3:  0.5055718475073313 \n",
      " F1 score of HorseRankTop50Percent:  0.7183563287342531\n"
     ]
    }
   ],
   "source": [
    "print(' F1 score of HorseWin: ' , f1_score(y_test['HorseWin'],b['HorseWin']),'\\n', 'F1 score of HorseRankTop3: ',\n",
    "      f1_score(y_test['HorseRankTop3'],b['HorseRankTop3']),'\\n', 'F1 score of HorseRankTop50Percent: ',\n",
    "      f1_score(y_test['HorseRankTop50Percent'],b['HorseRankTop50Percent']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 SVM Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM: Non-probabilistic binary classifier. The core of SVM is to maximize the margin between different classes. It can be used for linear classification or non-linear classification depends on its kernel function evaluated at a subset of training data points. The intuition of SVM is like if we cannot find a linearly separable hyperplane in the original space of X, we try to find a linearly separable hyperplane in the space spanned by higher order of X like Z=X^2. It mainly utilizes kernel function to realize the goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = SVC(kernel = 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes a while to run\n",
    "score_svm_Win = cross_val_score(svm_model,X_train,y_train['HorseWin'],cv = kfold,scoring = 'f1')\n",
    "score_svm_Top3 = cross_val_score(svm_model,X_train,y_train['HorseRankTop3'],cv = kfold,scoring = 'f1')\n",
    "score_svm_Top50 = cross_val_score(svm_model,X_train,y_train['HorseRankTop50Percent'],cv = kfold,scoring = 'f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cross Validation score for SVC: \",'\\n', \"HorseWin: \",score_svm_Win,'\\n',\"HorseTop3: \", \n",
    "      score_svm_Top3,'\\n',\"HorseTop50Percent: \", score_svm_Top50 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM takes a while to predict\n",
    "\n",
    "start_time4 = time.time()\n",
    "svm_model.fit(X_train,y_train['HorseWin'])\n",
    "svm_Win = svm_model.predict(X_test)\n",
    "svm_model.fit(X_train,y_train['HorseRankTop3'])\n",
    "svm_Top3 = svm_model.predict(X_test)\n",
    "svm_model.fit(X_train,y_train['HorseRankTop50Percent'])\n",
    "svm_Top50 = svm_model.predict(X_test)\n",
    "print('Running time for SVM is:',time.time() - start_time4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = pd.DataFrame()\n",
    "c['RaceID'] = testing['race_id']\n",
    "c['HorseID'] = testing['horse_id']\n",
    "c['HorseWin'] = svm_Win\n",
    "c['HorseRankTop3'] = svm_Top3\n",
    "c['HorseRankTop50Percent'] = svm_Top50\n",
    "c.to_csv('svm_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' F1 score of HorseWin: ' , f1_score(y_test['HorseWin'],c['HorseWin']),'\\n', 'F1 score of HorseRankTop3: ',\n",
    "      f1_score(y_test['HorseRankTop3'],c['HorseRankTop3']),'\\n', 'F1 score of HorseRankTop50Percent: ',\n",
    "      f1_score(y_test['HorseRankTop50Percent'],c['HorseRankTop50Percent']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " A random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and use averaging to improve the predictive accuracy and control over-fitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_rf_Win = cross_val_score(rf_model,X_train,y_train['HorseWin'],cv = kfold,scoring = 'f1')\n",
    "score_rf_Top3 = cross_val_score(rf_model,X_train,y_train['HorseRankTop3'],cv = kfold,scoring = 'f1')\n",
    "score_rf_Top50 = cross_val_score(rf_model,X_train,y_train['HorseRankTop50Percent'],cv = kfold,scoring = 'f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cross Validation score for Random Forest: \", \"HorseWin: \",score_rf_Win,'\\n',\"HorseTop3: \", \n",
    "      score_rf_Top3,'\\n',\"HorseTop50Percent: \", score_rf_Top50 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time5 = time.time()\n",
    "rf_model.fit(X_train,y_train['HorseWin'])\n",
    "rf_Win = rf_model.predict(X_test)\n",
    "rf_model.fit(X_train,y_train['HorseRankTop3'])\n",
    "rf_Top3 = rf_model.predict(X_test)\n",
    "rf_model.fit(X_train,y_train['HorseRankTop50Percent'])\n",
    "rf_Top50 = rf_model.predict(X_test)\n",
    "print('Running time for Random Forest is:',time.time() - start_time5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.DataFrame()\n",
    "d['RaceID'] = testing['race_id']\n",
    "d['HorseID'] = testing['horse_id']\n",
    "d['HorseWin'] = rf_Win\n",
    "d['HorseRankTop3'] = rf_Top3\n",
    "d['HorseRankTop50Percent'] = rf_Top50\n",
    "d.to_csv('rf_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' F1 score of HorseWin: ' , f1_score(y_test['HorseWin'],d['HorseWin']),'\\n', 'F1 score of HorseRankTop3: ',\n",
    "      f1_score(y_test['HorseRankTop3'],d['HorseRankTop3']),'\\n', 'F1 score of HorseRankTop50Percent: ',\n",
    "      f1_score(y_test['HorseRankTop50Percent'],d['HorseRankTop50Percent']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Support Vector Regression Model (SVR) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv('training.csv')\n",
    "testing = pd.read_csv('testing.csv')\n",
    "X_train = training[['actual_weight','declared_horse_weight','draw','win_odds','jockey_ave_rank','trainer_ave_rank',\n",
    "'recent_ave_rank','race_distance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train0 = training['finish_time']\n",
    "y_train = []\n",
    "for i in range(len(y_train0)):\n",
    "    sep = y_train0[i].split('.')\n",
    "    y_train.append(int(sep[0]) * 60 + int(sep[1]) + int(sep[2]) / 100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = testing[['actual_weight','declared_horse_weight','draw','win_odds','jockey_ave_rank','trainer_ave_rank',\n",
    "'recent_ave_rank','race_distance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = []\n",
    "y_test0 = testing['finish_time']\n",
    "for i in range(len(y_test0)):\n",
    "    sep = y_test0[i].split('.')\n",
    "    y_test.append(int(sep[0]) * 60 + int(sep[1]) + int(sep[2]) / 100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1_index = testing.index[testing['finishing_position']==1].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation:\n",
    "1. MSE\n",
    "2. Top_1: the percentage/probality when your prediction of top_1 horse(horse with shortest finish_time) for each race is actually the true top_1 horse.\n",
    "\n",
    "3. Top_3: percentage/probability when your prediction of top_1 horse for each race is actually within true top_3 horses for each race. \n",
    "\n",
    "4. Average_rank: the average true rank of top_1 horse based on your prediction over all races.\n",
    "\n",
    "For example, when you predict for 3 races and your predicted top_1 horse is actually ranking 1, 3, 5 in these races. Top_1 is 1/3, Top_3 is 2/3 and Average_Rank is 3.0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluation(predict):\n",
    "    top1_predict_index = []\n",
    "    for i in range(len(top1_index)-1):\n",
    "        temp = np.argmin(predict[top1_index[i]:top1_index[i + 1]])\n",
    "        top1_predict_index.append(top1_index[i] + temp)\n",
    "    temp0 = np.argmin(predict[top1_index[len(top1_index) - 1]:])\n",
    "    top1_predict_index.append(top1_index[len(top1_index) - 1] + temp0)\n",
    "\n",
    "    RMSE = math.sqrt(sum((np.array(predict) - np.array(y_test)) ** 2)) / len(y_test)\n",
    "    TOP_1 = float(len(set(top1_predict_index) & set(top1_index))) / len(top1_predict_index)\n",
    "\n",
    "    TOP_3 = (testing['finishing_position'][top1_predict_index].tolist().count(1) + testing['finishing_position'][top1_predict_index].tolist().count(2)\\\n",
    "          + testing['finishing_position'][top1_predict_index].tolist().count(3)) / float(len(top1_predict_index))\n",
    "    Average_Rank = sum(testing['finishing_position'][top1_predict_index]) / float(len(top1_predict_index))\n",
    "    return (RMSE,TOP_1,TOP_3,Average_Rank)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning parameters for SVR\n",
    "\n",
    "C is penalty parameter for error. If C is large, it means high penalty for error, which may cause overfitting; while if C is small, it means flat margins, which may cause under-fitting. Epsilon specifies the range of no-penalty district around margin. Larger epsilon means higher tolerance of error.\n",
    "\n",
    "Conducted small scale grid search for selection of C and epsilon. I tried values from 2^(-4) to 2^(2) for both C and epsilon, and I found C and epsilon actually do not have significant effect on the results with regard to 4 evaluation statistics. I choose the relative better pair of (C, epsilon)=( 2^(-2), 2^(-4) )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_model = SVR(kernel = 'linear', C = math.pow(2,-2), epsilon = math.pow(2,-4))\n",
    "svr_model.fit(X_train, y_train)\n",
    "svr_predict = svr_model.predict(X_test)\n",
    "print('Evaluation statistics for SVR model:',Evaluation(svr_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###---Normalization----###\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_trans = scaler.transform(X_train)\n",
    "yy = pd.DataFrame()\n",
    "yy['finish_time'] = y_train\n",
    "scaler1 = StandardScaler().fit(yy)\n",
    "y_train_trans = scaler1.transform(yy)\n",
    "X_test_trans = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit normalized data to svr_model\n",
    "svr_model.fit(X_train_trans,y_train_trans)\n",
    "svr_predict_norm = svr_model.predict(X_test_trans)\n",
    "svr_norm_evaluation = Evaluation(svr_predict_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use training data mean and variance to get RMSE after normalization\n",
    "y_test_norm = (np.array(y_test)-scaler1.mean_) / math.sqrt(scaler1.var_)\n",
    "svr_norm_RMSE = math.sqrt(sum((np.array(svr_predict_norm) - y_test_norm) ** 2)) / len(y_test)\n",
    "print('Normalized evaluation statistics for SVR model:',(svr_norm_RMSE,) + svr_norm_evaluation[1:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Gradient Boosting Regression Tree Model (GBRT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting Regression Tree Model is a generalization of boosting technique to arbitrary differentiable loss functions.\n",
    "It is used here becauese of its natural handling of data of mixed type, great predictive power and robustness to outliers in output space (via robust loss functions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning Parameters for GBRT:\n",
    "Loss function: It has various loss functions including ls, lad, huber, quantile. Choose loss=’qunatile’, since for default values of other parameters, this loss function performs best according to TOP_1 and TOP_3 evaluation statistics.\n",
    "\n",
    "learning_rate: controls the contribution of each weak classifier (tree).\n",
    "\n",
    "n_estimators: represents the number of weak learners (tree). Since boosting combines the output of many weak classifiers, the larger n_estimators, the more robust the model is and the better results are.\n",
    "\n",
    "max_depth: maximum nodes of the tree\n",
    "\n",
    "I chose learning_rate = 0.01, n_estimators = 10, max_depth = 2, since I found by assigning these three values to parameters, TOP_1 = 0.99, TOP_3 = 1, which performs the best in predicting winner of horse races."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbrt_model = GradientBoostingRegressor(loss = 'quantile',learning_rate = 0.01, n_estimators = 10, max_depth = 2)\n",
    "gbrt_model.fit(X_train,y_train)\n",
    "gbrt_predict = gbrt_model.predict(X_test)\n",
    "print('Evaluation statistics for GBRT model:' , Evaluation(gbrt_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit normalized data to gbrt_model\n",
    "gbrt_model.fit(X_train_trans,y_train_trans)\n",
    "gbrt_predict_norm = gbrt_model.predict(X_test_trans)\n",
    "gbrt_norm_evaluation = Evaluation(gbrt_predict_norm)\n",
    "\n",
    "# use training data mean and variance to get RMSE after normalization\n",
    "gbrt_norm_RMSE = math.sqrt(sum((np.array(gbrt_predict_norm) - y_test_norm) ** 2)) / len(y_test)\n",
    "print('Normalized evaluation statistics for GBRT model:',(gbrt_norm_RMSE,) + gbrt_norm_evaluation[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pd.DataFrame()\n",
    "f['RaceID'] = testing['race_id']\n",
    "f['HorseID'] = testing['horse_id']\n",
    "f['svr_predict'] = svr_predict\n",
    "f['svr_predict_norm'] = svr_predict_norm\n",
    "f['gbrt_predict'] = gbrt_predict\n",
    "f['gbrt_predict_norm'] = gbrt_predict_norm\n",
    "f.to_csv('reg_prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V. Betting Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Betting strategy is to bet all $1 for the predicted winning horse for each race. \n",
    "\n",
    "Concretely, if our prediction is correct for the winning horse, we will receive $1 × odds money. \n",
    "\n",
    "Otherwise, we will lose $1. \n",
    "\n",
    "The final result is positive if we win some money and negative if we lose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 4 classification models, if there are more than 1 HorseWin in a race in predictions, I will choose the one with smallest odds, since as odds increase, winning probability decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = pd.read_csv('testing.csv')\n",
    "champion_index = testing[testing['HorseWin'] == 1].index.tolist()\n",
    "champion_odds = testing[testing['HorseWin'] == 1]['win_odds'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_range_in_list(li, min, max):\n",
    "    ctr = 0\n",
    "    for x in li:\n",
    "        if min <= x <= max:\n",
    "            ctr += 1\n",
    "    return ctr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ele_in_list(li, min, max):\n",
    "    ele = []\n",
    "    for x in li:\n",
    "        if min <= x <= max:\n",
    "            ele.append(x)\n",
    "    return ele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def betting_result(champion_odds,champion_index,prediction):\n",
    "    money=0\n",
    "    for i in range(len(champion_index)-1):\n",
    "        ctr= count_range_in_list(prediction,champion_index[i],champion_index[i+1]-1)\n",
    "        if ctr==0:\n",
    "            money=money-1\n",
    "        elif ctr==1:\n",
    "            money=money-1+champion_odds[i]\n",
    "        else:\n",
    "            ele_list=ele_in_list(prediction,champion_index[i],champion_index[i+1]-1)\n",
    "            if min(ele_list)==champion_index[i]:\n",
    "                money=money-1+champion_odds[i]\n",
    "            else:\n",
    "                money=money-1\n",
    "    ctr = count_range_in_list(prediction, champion_index[len(champion_index)-1],len(testing['HorseWin'])-1)\n",
    "    if ctr == 0:\n",
    "        money = money - 1\n",
    "    elif ctr == 1:\n",
    "        money = money - 1 + champion_odds[len(champion_index)-1]\n",
    "    else:\n",
    "        ele_list = ele_in_list(prediction, champion_index[len(champion_index)-1], len(testing['HorseWin'])-1)\n",
    "        if min(ele_list)==champion_index[len(champion_index)-1]:\n",
    "            money = money - 1 + champion_odds[len(champion_index)-1]\n",
    "        else:\n",
    "            money = money - 1\n",
    "    return money"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = pd.read_csv('lr_predictions.csv')\n",
    "lr_index = lr[lr['HorseWin'] == 1].index.tolist()\n",
    "print('Betting result for Logistic Regression model:',betting_result(champion_odds,champion_index,lr_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = pd.read_csv('nb_predictions.csv')\n",
    "nb_index = nb[nb['HorseWin'] == 1].index.tolist()\n",
    "print('Betting result for Naive Bayes model:', betting_result(champion_odds,champion_index,nb_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = pd.read_csv('rf_predictions.csv')\n",
    "rf_index = rf[rf['HorseWin'] == 1].index.tolist()\n",
    "print('Betting result for Random Forest model:',betting_result(champion_odds,champion_index,rf_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = pd.read_csv('svm_predictions.csv')\n",
    "svm_index = svm[svm['HorseWin'] == 1].index.tolist()\n",
    "print('Betting result for SVM model:',betting_result(champion_odds,champion_index,svm_index))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 4 regression models, I choose the horse with shortest predicted finish_time as the unique winning horse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(predict):\n",
    "    top1_predict_index = []\n",
    "    for i in range(len(champion_index)-1):\n",
    "        temp = np.argmin(predict[champion_index[i]:champion_index[i + 1]])\n",
    "        top1_predict_index.append(champion_index[i]+temp)\n",
    "    temp0 = np.argmin(predict[champion_index[len(champion_index) - 1]:])\n",
    "    top1_predict_index.append(champion_index[len(champion_index) - 1] + temp0)\n",
    "    return top1_predict_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_prediction = pd.read_csv('reg_prediction.csv')\n",
    "reg_svr = reg_prediction['svr_predict']\n",
    "reg_svr_norm = reg_prediction['svr_predict_norm']\n",
    "reg_gbrt = reg_prediction['gbrt_predict']\n",
    "reg_gbrt_norm = reg_prediction['gbrt_predict_norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_index = prediction(reg_svr)\n",
    "svr_norm_index = prediction(reg_svr_norm)\n",
    "gbrt_index = prediction(reg_gbrt)\n",
    "gbrt_norm_index = prediction(reg_gbrt_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Betting result for SVR model:',betting_result(champion_odds,champion_index,svr_index))\n",
    "print('Betting result for SVR (Normalized) model:',betting_result(champion_odds,champion_index,svr_norm_index))\n",
    "print('Betting result for GBRT model:',betting_result(champion_odds,champion_index,gbrt_index))\n",
    "print('Betting result for GBRT (Normalized) model:',betting_result(champion_odds,champion_index,gbrt_norm_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It seems 2 regression algorithms perform well and normalization improves performance of SVR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Improvement:\n",
    "\n",
    "I set threshold for the average rank and odds. For example, we only bet the horse whose odd is in the smallest 5, and recent_ave_rank is also in smallest 5. This means we decreases the risk of betting in horses with bad recent performance. If the horse cannot satisfy the criteria, we do not bet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imp_betting(champion_odds,champion_index,prediction):\n",
    "    money = 0\n",
    "    for i in range(len(champion_index) - 1):\n",
    "        ctr = count_range_in_list(prediction, champion_index[i], champion_index[i + 1] - 1)\n",
    "        if ctr >= 1:\n",
    "            temp_odds = testing['win_odds'].tolist()[champion_index[i]:champion_index[i + 1]]\n",
    "            temp_ave_rank = testing['recent_ave_rank'].tolist()[champion_index[i]:champion_index[i + 1]]\n",
    "            seq_odds = sorted(temp_odds)\n",
    "            seq_ave_rank = sorted(temp_ave_rank)\n",
    "            ele_list = ele_in_list(prediction,champion_index[i],champion_index[i+1]-1)\n",
    "            if (seq_odds.index(testing['win_odds'][ele_list[0]]) <= 5) and (seq_ave_rank.index(testing['recent_ave_rank'][ele_list[0]]) <= 5):\n",
    "                money = money - 1\n",
    "                if ele_list[0] == champion_index[i]:\n",
    "                    money = money + champion_odds[i]\n",
    "    return money\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Improved betting result for Logistic Regression model:',imp_betting(champion_odds,champion_index,lr_index))\n",
    "print('Improved betting result for Naive Bayes model:',imp_betting(champion_odds,champion_index,nb_index))\n",
    "print('Improved betting result for Random Forest model:',imp_betting(champion_odds,champion_index,rf_index))\n",
    "print('Improved betting result for SVR model:',imp_betting(champion_odds,champion_index,svr_index))\n",
    "print('Improved betting result fo GBRT model:',imp_betting(champion_odds,champion_index,gbrt_index))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, it seems that setting threshold cannot improve the results for those method whose results are already positive. It only decreases losses by decreasing risk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VI. Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Line Chart of Recent Racing Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the history racing result of some specific horse.\n",
    "\n",
    "Interactive: takes a horse ID as input, and outputs a line chart that shows the finishing positions of 6 recent races that the horse attended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linechart(horse_id):\n",
    "    recent_6_runs = training[training.horse_id == horse_id]['recent_6_runs'][-1:].tolist()[0]\n",
    "\n",
    "    recent_6_runs = list(map(int,recent_6_runs.split('/')))[::-1]\n",
    "    print(recent_6_runs)\n",
    "    game_id = training[training.horse_id == horse_id][['race_id']][-6:]\n",
    "    print(game_id)\n",
    "    plt.plot(game_id.iloc[:,0], recent_6_runs, marker = '+')\n",
    "    plt.xlabel('Game_id')\n",
    "    plt.ylabel('Ranks of recent 6 runs')\n",
    "    plt.title('Line Chart of recent 6 runs'+'- Horse ' + horse_id)\n",
    "    plt.ylim((0, 14))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv('training.csv')\n",
    "horse_id = 'S047'\n",
    "linechart(horse_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Scatter Plot of Win Rate and Number of Wins "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The x-axis is the win rate, and the y-axis is the number of wins. \n",
    "\n",
    "Set a threshold and label the name of the horses (or jockeys) who reach the threshold. E.g., if a horse’s win rate is larger than 0.5, and wins more than 4 games, then you should annotate the point of this horse with its name. \n",
    "\n",
    "Goal: to find the “best” horse and the “best” jockey. Intuitively, the “best” one should have a high win rate and have won a large number of games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv('training.csv')\n",
    "jockey = training.jockey.unique()\n",
    "a = pd.DataFrame()\n",
    "a['jockey'] = jockey\n",
    "a['no_win'] = 0\n",
    "a['win_rate'] = 0.0\n",
    "for i in range(len(jockey)):\n",
    "    ranks = training[training.jockey == jockey[i]]['finishing_position'].tolist()\n",
    "    a['no_win'][i] = ranks.count(1)\n",
    "    a['win_rate'][i] = ranks.count(1) / float(len(ranks))\n",
    "\n",
    "horse = training.horse_name.unique()\n",
    "b = pd.DataFrame()\n",
    "b['horse'] = horse\n",
    "b['no_win'] = 0\n",
    "b['win_rate'] = 0.0\n",
    "for i in range(len(jockey)):\n",
    "    ranks=training[training.horse_name == horse[i]]['finishing_position'].tolist()\n",
    "    b['no_win'][i] = ranks.count(1)\n",
    "    b['win_rate'][i] = ranks.count(1) / float(len(ranks))\n",
    "\n",
    "figure(num = None, figsize = (12, 12), dpi = 90, facecolor = 'w', edgecolor = 'k')\n",
    "plt.subplot(2,1,1)\n",
    "plt.scatter(a['win_rate'],a['no_win'],alpha = 0.3)\n",
    "plt.title('Scatter plot for jockeys')\n",
    "plt.xlabel('Win Rate')\n",
    "plt.ylabel('Number of Wins')\n",
    "for i in range(len(jockey)):\n",
    "    if a['no_win'][i] >= 10 and a['win_rate'][i] >= 0.06:\n",
    "        plt.annotate(a['jockey'][i],(a['win_rate'][i],a['no_win'][i]),size = 7)\n",
    "\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.scatter(b['win_rate'],b['no_win'],alpha=0.3)\n",
    "plt.title('Scatter plot for horses')\n",
    "plt.xlabel('Win Rate')\n",
    "plt.ylabel('Number of Wins')\n",
    "for i in range(len(horse)):\n",
    "    if b['no_win'][i] >= 2 and b['win_rate'][i] >= 0.15:\n",
    "        plt.annotate(b['horse'][i],(b['win_rate'][i],b['no_win'][i]),size = 7)\n",
    "        \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best jockey is J Moreira. Since he has the highest number of wins and very high win rate.\n",
    "\n",
    "\n",
    "The best horse is Romantic Cash, since it has the highest win rate and its ranks are very stable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Pie Chart of the Draw Bias Effect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pie chart is a way to visualize the distribution of categorical data\n",
    "\n",
    "#### Goal: explore the effect of draw bias in horse racing. \n",
    "\n",
    "The draw refers to the stall a horse will start the race from. The draw is normally chosen at random on the day the horses are declared to run. Obviously, the inside lane would hold an edge over the field as they have a shorter distance to the bend, in comparison to the other lanes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv('training.csv')\n",
    "\n",
    "win_prob = []\n",
    "for i in range(1,16,1):\n",
    "    win_prob.append(training[training.draw == i]['finishing_position'].tolist().count(1) / float(len(training[training.draw == i])))\n",
    "\n",
    "print(win_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['1','2','3','4','5','6','7','8','9','10','11','12','13','14','15']\n",
    "figure(num = None, figsize = (8, 8), dpi = 90, facecolor = 'w', edgecolor = 'k')\n",
    "plt.pie(win_prob,labels = labels,autopct = '%1.1f%%', colors = sns.color_palette(\"cubehelix\"))\n",
    "plt.title('Pie Chart of the Draw Bias Effect (Number represents No. of lane the horse will run)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Low draws indeed have a considerable advantage, as we can see that as draw increases, the winning probability decreases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Bar Chart of the Feature Importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use random forest classifier to evaluate the importance of the features, which measures how much each feature decreases the weighted impurity in a tree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv('training.csv')\n",
    "rf_model = RandomForestClassifier()\n",
    "X_train = training[['actual_weight','declared_horse_weight','draw','win_odds','jockey_ave_rank','trainer_ave_rank',\n",
    "'recent_ave_rank','race_distance']]\n",
    "y_train = training[['HorseWin','HorseRankTop3','HorseRankTop50Percent']]\n",
    "rf_model.fit(X_train,y_train['HorseWin'])\n",
    "features = 'actual_weight','declared_horse_weight','draw','win_odds','jockey_ave_rank','trainer_ave_rank','recent_ave_rank','race_distance'\n",
    "importance = rf_model.feature_importances_\n",
    "indices = np.argsort(importance)[::-1]\n",
    "print(importance[indices])\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(num = None, figsize = (8, 6), dpi = 90, facecolor = 'w', edgecolor = 'k')\n",
    "plt.bar(range(len(features)),importance[indices],color = sns.color_palette(\"RdBu_r\", 8))\n",
    "plt.xticks(range(len(features)),features)\n",
    "plt.xlabel('Feature names')\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Bar Chart of the Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We find that actual_weight, declared_horse_weight and draw affect the most, while race_distance has the least effect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Visualize SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it is hard to visualize high-dimensional data, for the input data X, we only consider these two features: recent_rank and jockey_ave_rank. Also, for the target y, we only care about whether the finishing position is in top 50%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv('training.csv')\n",
    "X = training[['recent_ave_rank','jockey_ave_rank']]\n",
    "y = training['HorseRankTop50Percent']\n",
    "svm_model = SVC(kernel = 'linear')\n",
    "svm_model.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_meshgrid(x, y, h = .02):\n",
    "\n",
    "    x_min, x_max = x.min() - 1, x.max() + 1\n",
    "    y_min, y_max = y.min() - 1, y.max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    return xx, yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_contours(clf, xx, yy, **params):\n",
    "\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    out = plt.contourf(xx, yy, Z, **params)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0, X1 = X['recent_ave_rank'], X['jockey_ave_rank']\n",
    "xx, yy = make_meshgrid(X0, X1)\n",
    "\n",
    "figure(num = None, figsize = (8, 6), dpi = 90, facecolor = 'w', edgecolor = 'k')\n",
    "plot_contours(svm_model,xx, yy, alpha = 0.8)\n",
    "plt.scatter(X0, X1, c = y,  s = 20, edgecolors = 'k')\n",
    "plt.title('Visualized SVM')\n",
    "plt.xlabel('Recent average rank')\n",
    "plt.ylabel('Jockey average rank')\n",
    "patch = mpatches.Patch(color = 'purple',label = 'SVC(kernel=\\'linear\\')')\n",
    "plt.legend(handles = [patch])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear kernel seems not bad in two-feature SVM classification. But there are still plenty of points cross the margin which cannot be classified correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
