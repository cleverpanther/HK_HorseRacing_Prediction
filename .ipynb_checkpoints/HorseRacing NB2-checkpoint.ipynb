{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the train and test files\n",
    "training = pd.read_csv('training.csv')\n",
    "testing = pd.read_csv('testing.csv')\n",
    "\n",
    "\n",
    "X_train = training[['actual_weight','declared_horse_weight','draw','win_odds','jockey_ave_rank','trainer_ave_rank',\n",
    "'recent_ave_rank','race_distance']]\n",
    "y_train = training[['HorseWin','HorseRankTop3','HorseRankTop50Percent']]\n",
    "\n",
    "X_test = testing[['actual_weight','declared_horse_weight','draw','win_odds','jockey_ave_rank','trainer_ave_rank',\n",
    "'recent_ave_rank','race_distance']]\n",
    "y_test = testing[['HorseWin','HorseRankTop3','HorseRankTop50Percent']]\n",
    "\n",
    "kfold = KFold(n_splits = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual_weight</th>\n",
       "      <th>declared_horse_weight</th>\n",
       "      <th>draw</th>\n",
       "      <th>win_odds</th>\n",
       "      <th>jockey_ave_rank</th>\n",
       "      <th>trainer_ave_rank</th>\n",
       "      <th>recent_ave_rank</th>\n",
       "      <th>race_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>133</td>\n",
       "      <td>1032</td>\n",
       "      <td>1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.052910</td>\n",
       "      <td>7.381862</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>133</td>\n",
       "      <td>1075</td>\n",
       "      <td>13</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.825153</td>\n",
       "      <td>6.611465</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>121</td>\n",
       "      <td>1065</td>\n",
       "      <td>3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>7.857759</td>\n",
       "      <td>6.888713</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>1222</td>\n",
       "      <td>2</td>\n",
       "      <td>6.1</td>\n",
       "      <td>4.179172</td>\n",
       "      <td>6.680328</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>125</td>\n",
       "      <td>1136</td>\n",
       "      <td>9</td>\n",
       "      <td>6.1</td>\n",
       "      <td>5.284127</td>\n",
       "      <td>6.903955</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23495</th>\n",
       "      <td>121</td>\n",
       "      <td>1075</td>\n",
       "      <td>5</td>\n",
       "      <td>19.0</td>\n",
       "      <td>8.103093</td>\n",
       "      <td>8.121951</td>\n",
       "      <td>5.850000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23496</th>\n",
       "      <td>130</td>\n",
       "      <td>1203</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.440841</td>\n",
       "      <td>7.369128</td>\n",
       "      <td>6.903226</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23497</th>\n",
       "      <td>129</td>\n",
       "      <td>1237</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.330365</td>\n",
       "      <td>6.715420</td>\n",
       "      <td>5.454545</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23498</th>\n",
       "      <td>114</td>\n",
       "      <td>1141</td>\n",
       "      <td>3</td>\n",
       "      <td>87.0</td>\n",
       "      <td>7.464696</td>\n",
       "      <td>7.177492</td>\n",
       "      <td>9.833333</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23499</th>\n",
       "      <td>123</td>\n",
       "      <td>1071</td>\n",
       "      <td>7</td>\n",
       "      <td>47.0</td>\n",
       "      <td>8.535494</td>\n",
       "      <td>7.381862</td>\n",
       "      <td>5.052632</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23500 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       actual_weight  declared_horse_weight  draw  win_odds  jockey_ave_rank  \\\n",
       "0                133                   1032     1       3.8         6.052910   \n",
       "1                133                   1075    13       8.0         5.825153   \n",
       "2                121                   1065     3       5.7         7.857759   \n",
       "3                132                   1222     2       6.1         4.179172   \n",
       "4                125                   1136     9       6.1         5.284127   \n",
       "...              ...                    ...   ...       ...              ...   \n",
       "23495            121                   1075     5      19.0         8.103093   \n",
       "23496            130                   1203     1      17.0         7.440841   \n",
       "23497            129                   1237     2      18.0         7.330365   \n",
       "23498            114                   1141     3      87.0         7.464696   \n",
       "23499            123                   1071     7      47.0         8.535494   \n",
       "\n",
       "       trainer_ave_rank  recent_ave_rank  race_distance  \n",
       "0              7.381862         1.000000           1400  \n",
       "1              6.611465         2.000000           1400  \n",
       "2              6.888713         3.000000           1400  \n",
       "3              6.680328         4.000000           1400  \n",
       "4              6.903955         5.000000           1400  \n",
       "...                 ...              ...            ...  \n",
       "23495          8.121951         5.850000           1000  \n",
       "23496          7.369128         6.903226           1000  \n",
       "23497          6.715420         5.454545           1000  \n",
       "23498          7.177492         9.833333           1000  \n",
       "23499          7.381862         5.052632           1000  \n",
       "\n",
       "[23500 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation\n",
    "Cross validation can estimate the expected extra-sample error. Since static split of training and testing data cannot build a very good model given out-of-sample data, CV efficiently utilizes the data and also improves performance in predicting out-of-sample data, thus avoiding overfitting problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\finan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\finan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\finan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\finan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\finan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\finan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\finan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\finan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\finan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation score for Logistic Regression: \n",
      " HorseWin:  [0.05128205 0.05684755 0.03626943 0.03626943 0.04639175] \n",
      " HorseTop3:  [0.62089259 0.42474717 0.43452022 0.39785587 0.35264798] \n",
      " HorseTop50Percent:  [0.79868394 0.72073965 0.70459247 0.69849041 0.68211649]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\finan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\finan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "score_lr_Win = cross_val_score(lr_model,X_train,y_train['HorseWin'],cv = kfold,scoring = 'f1')\n",
    "score_lr_Top3 = cross_val_score(lr_model,X_train,y_train['HorseRankTop3'],cv = kfold,scoring = 'f1')\n",
    "score_lr_Top50 = cross_val_score(lr_model,X_train,y_train['HorseRankTop50Percent'],cv = kfold,scoring = 'f1')\n",
    "print(\"Cross Validation score for Logistic Regression:\",'\\n', \"HorseWin: \",score_lr_Win,'\\n',\"HorseTop3: \", \n",
    "      score_lr_Top3,'\\n',\"HorseTop50Percent: \", score_lr_Top50 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Predictions \n",
    "\n",
    "HorseWin: If the horse was in the first finish speeds, ‘1’ else ‘0’.\n",
    "\n",
    "HorseRankTop3: If the horse was in the top 3 finish speeds, ‘1’ else ‘0’.\n",
    "\n",
    "HorseRankTop50Percent: If the horse was in the top 50 percent finish speeds, ’1’ else ‘0’.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time for logistic rergession is:  0.27295398712158203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\finan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\finan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "start_time1 = time.time()\n",
    "lr_model.fit(X_train,y_train['HorseWin'])\n",
    "lr_Win = lr_model.predict(X_test)\n",
    "lr_model.fit(X_train,y_train['HorseRankTop3'])\n",
    "lr_Top3 = lr_model.predict(X_test)\n",
    "lr_model.fit(X_train,y_train['HorseRankTop50Percent'])\n",
    "lr_Top50 = lr_model.predict(X_test)\n",
    "print('Running time for logistic rergession is: ' , time.time() - start_time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write predictions into csv file.\n",
    "a = pd.DataFrame()\n",
    "a['RaceID'] = testing['race_id']\n",
    "a['HorseID'] = testing['horse_id']\n",
    "a['HorseWin'] = lr_Win\n",
    "a['HorseRankTop3'] = lr_Top3\n",
    "a['HorseRankTop50Percent'] = lr_Top50\n",
    "a.to_csv('lr_predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of Predictions _ F1 score\n",
    "\n",
    "Reasons of choosing F1: For imbalanced data, 1 is more important than 0, model may try to increase accuracy by predicting all 0, while in this case, f1 score is close to 0 while accuracy is close to 1. So for imbalanced data, f1 score (similarly TNR, NPV) is good choice.\n",
    "\n",
    "F1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "Precision P = TP / (TP + FP), probability that one classified positive instance is classified correctly.\n",
    "\n",
    "Recall R = TP / (TP +FN) , percentage of truly positive instances correctly classified. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " F1 score of HorseWin:  0.0529531568228106 \n",
      " F1 score of HorseRankTop3:  0.3595617529880478 \n",
      " F1 score of HorseRankTop50Percent:  0.693624653513778\n"
     ]
    }
   ],
   "source": [
    "print(' F1 score of HorseWin: ' , f1_score(y_test['HorseWin'],a['HorseWin']),'\\n', 'F1 score of HorseRankTop3: ',\n",
    "      f1_score(y_test['HorseRankTop3'],a['HorseRankTop3']),'\\n', 'F1 score of HorseRankTop50Percent: ',\n",
    "      f1_score(y_test['HorseRankTop50Percent'],a['HorseRankTop50Percent']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Naïve Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised learning algorithms based on applying Bayes’ theorem with the “naive” assumption of independence between every pair of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation score for Naive Bayes:  \n",
      " HorseWin:  [0.36181818 0.34763476 0.31038251 0.28542304 0.28210526] \n",
      " HorseTop3:  [0.61533173 0.53181818 0.53748126 0.51724138 0.51145602] \n",
      " HorseTop50Percent:  [0.7785575  0.72748447 0.7187017  0.71444738 0.71051152]\n"
     ]
    }
   ],
   "source": [
    "score_nb_Win=cross_val_score(nb_model,X_train,y_train['HorseWin'],cv=kfold,scoring='f1')\n",
    "score_nb_Top3=cross_val_score(nb_model,X_train,y_train['HorseRankTop3'],cv=kfold,scoring='f1')\n",
    "score_nb_Top50=cross_val_score(nb_model,X_train,y_train['HorseRankTop50Percent'],cv=kfold,scoring='f1')\n",
    "print(\"Cross Validation score for Naive Bayes: \",'\\n', \"HorseWin: \",score_nb_Win,'\\n',\"HorseTop3: \", \n",
    "      score_nb_Top3,'\\n',\"HorseTop50Percent: \", score_nb_Top50 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time for Naive Bayes in scikit-learn is:  0.026884794235229492\n"
     ]
    }
   ],
   "source": [
    "start_time2 = time.time()\n",
    "nb_model.fit(X_train,y_train['HorseWin'])\n",
    "nb_Win = nb_model.predict(X_test)\n",
    "nb_model.fit(X_train,y_train['HorseRankTop3'])\n",
    "nb_Top3 = nb_model.predict(X_test)\n",
    "nb_model.fit(X_train,y_train['HorseRankTop50Percent'])\n",
    "nb_Top50 = nb_model.predict(X_test)\n",
    "print('Running time for Naive Bayes in scikit-learn is: ' , time.time()-start_time2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.DataFrame()\n",
    "b['RaceID'] = testing['race_id']\n",
    "b['HorseID'] = testing['horse_id']\n",
    "b['HorseWin'] = nb_Win\n",
    "b['HorseRankTop3'] = nb_Top3\n",
    "b['HorseRankTop50Percent'] = nb_Top50\n",
    "b.to_csv('nb_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " F1 score of HorseWin:  0.2820945945945946 \n",
      " F1 score of HorseRankTop3:  0.5055718475073313 \n",
      " F1 score of HorseRankTop50Percent:  0.7183563287342531\n"
     ]
    }
   ],
   "source": [
    "print(' F1 score of HorseWin: ' , f1_score(y_test['HorseWin'],b['HorseWin']),'\\n', 'F1 score of HorseRankTop3: ',\n",
    "      f1_score(y_test['HorseRankTop3'],b['HorseRankTop3']),'\\n', 'F1 score of HorseRankTop50Percent: ',\n",
    "      f1_score(y_test['HorseRankTop50Percent'],b['HorseRankTop50Percent']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 SVM Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM: Non-probabilistic binary classifier. The core of SVM is to maximize the margin between different classes. It can be used for linear classification or non-linear classification depends on its kernel function evaluated at a subset of training data points. The intuition of SVM is like if we cannot find a linearly separable hyperplane in the original space of X, we try to find a linearly separable hyperplane in the space spanned by higher order of X like Z=X^2. It mainly utilizes kernel function to realize the goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_model = SVC(kernel = 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Takes a while to run\n",
    "# score_svm_Win = cross_val_score(svm_model,X_train,y_train['HorseWin'],cv = kfold,scoring = 'f1')\n",
    "# score_svm_Top3 = cross_val_score(svm_model,X_train,y_train['HorseRankTop3'],cv = kfold,scoring = 'f1')\n",
    "# score_svm_Top50 = cross_val_score(svm_model,X_train,y_train['HorseRankTop50Percent'],cv = kfold,scoring = 'f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Cross Validation score for SVC: \",'\\n', \"HorseWin: \",score_svm_Win,'\\n',\"HorseTop3: \", \n",
    "#       score_svm_Top3,'\\n',\"HorseTop50Percent: \", score_svm_Top50 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SVM takes a while to predict\n",
    "\n",
    "# start_time4 = time.time()\n",
    "# svm_model.fit(X_train,y_train['HorseWin'])\n",
    "# svm_Win = svm_model.predict(X_test)\n",
    "# svm_model.fit(X_train,y_train['HorseRankTop3'])\n",
    "# svm_Top3 = svm_model.predict(X_test)\n",
    "# svm_model.fit(X_train,y_train['HorseRankTop50Percent'])\n",
    "# svm_Top50 = svm_model.predict(X_test)\n",
    "# print('Running time for SVM is:',time.time() - start_time4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = pd.DataFrame()\n",
    "# c['RaceID'] = testing['race_id']\n",
    "# c['HorseID'] = testing['horse_id']\n",
    "# c['HorseWin'] = svm_Win\n",
    "# c['HorseRankTop3'] = svm_Top3\n",
    "# c['HorseRankTop50Percent'] = svm_Top50\n",
    "# c.to_csv('svm_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(' F1 score of HorseWin: ' , f1_score(y_test['HorseWin'],c['HorseWin']),'\\n', 'F1 score of HorseRankTop3: ',\n",
    "#       f1_score(y_test['HorseRankTop3'],c['HorseRankTop3']),'\\n', 'F1 score of HorseRankTop50Percent: ',\n",
    "#       f1_score(y_test['HorseRankTop50Percent'],c['HorseRankTop50Percent']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " A random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and use averaging to improve the predictive accuracy and control over-fitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_rf_Win = cross_val_score(rf_model,X_train,y_train['HorseWin'],cv = kfold,scoring = 'f1')\n",
    "score_rf_Top3 = cross_val_score(rf_model,X_train,y_train['HorseRankTop3'],cv = kfold,scoring = 'f1')\n",
    "score_rf_Top50 = cross_val_score(rf_model,X_train,y_train['HorseRankTop50Percent'],cv = kfold,scoring = 'f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation score for Random Forest:  HorseWin:  [0.42774566 0.16587678 0.10268949 0.1253012  0.11876485] \n",
      " HorseTop3:  [0.64958917 0.44444444 0.42909535 0.41225962 0.37616387] \n",
      " HorseTop50Percent:  [0.77402819 0.70952483 0.69967983 0.68851766 0.68014319]\n"
     ]
    }
   ],
   "source": [
    "print(\"Cross Validation score for Random Forest: \", \"HorseWin: \",score_rf_Win,'\\n',\"HorseTop3: \", \n",
    "      score_rf_Top3,'\\n',\"HorseTop50Percent: \", score_rf_Top50 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time for Random Forest is: 6.654299736022949\n"
     ]
    }
   ],
   "source": [
    "start_time5 = time.time()\n",
    "rf_model.fit(X_train,y_train['HorseWin'])\n",
    "rf_Win = rf_model.predict(X_test)\n",
    "rf_model.fit(X_train,y_train['HorseRankTop3'])\n",
    "rf_Top3 = rf_model.predict(X_test)\n",
    "rf_model.fit(X_train,y_train['HorseRankTop50Percent'])\n",
    "rf_Top50 = rf_model.predict(X_test)\n",
    "print('Running time for Random Forest is:',time.time() - start_time5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.DataFrame()\n",
    "d['RaceID'] = testing['race_id']\n",
    "d['HorseID'] = testing['horse_id']\n",
    "d['HorseWin'] = rf_Win\n",
    "d['HorseRankTop3'] = rf_Top3\n",
    "d['HorseRankTop50Percent'] = rf_Top50\n",
    "d.to_csv('rf_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " F1 score of HorseWin:  0.16206261510128914 \n",
      " F1 score of HorseRankTop3:  0.38320987654320987 \n",
      " F1 score of HorseRankTop50Percent:  0.692294779251301\n"
     ]
    }
   ],
   "source": [
    "print(' F1 score of HorseWin: ' , f1_score(y_test['HorseWin'],d['HorseWin']),'\\n', 'F1 score of HorseRankTop3: ',\n",
    "      f1_score(y_test['HorseRankTop3'],d['HorseRankTop3']),'\\n', 'F1 score of HorseRankTop50Percent: ',\n",
    "      f1_score(y_test['HorseRankTop50Percent'],d['HorseRankTop50Percent']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Support Vector Regression Model (SVR) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv('training.csv')\n",
    "testing = pd.read_csv('testing.csv')\n",
    "X_train = training[['actual_weight','declared_horse_weight','draw','win_odds','jockey_ave_rank','trainer_ave_rank',\n",
    "'recent_ave_rank','race_distance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual_weight</th>\n",
       "      <th>declared_horse_weight</th>\n",
       "      <th>draw</th>\n",
       "      <th>win_odds</th>\n",
       "      <th>jockey_ave_rank</th>\n",
       "      <th>trainer_ave_rank</th>\n",
       "      <th>recent_ave_rank</th>\n",
       "      <th>race_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>133</td>\n",
       "      <td>1032</td>\n",
       "      <td>1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.052910</td>\n",
       "      <td>7.381862</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>133</td>\n",
       "      <td>1075</td>\n",
       "      <td>13</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.825153</td>\n",
       "      <td>6.611465</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>121</td>\n",
       "      <td>1065</td>\n",
       "      <td>3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>7.857759</td>\n",
       "      <td>6.888713</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>1222</td>\n",
       "      <td>2</td>\n",
       "      <td>6.1</td>\n",
       "      <td>4.179172</td>\n",
       "      <td>6.680328</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>125</td>\n",
       "      <td>1136</td>\n",
       "      <td>9</td>\n",
       "      <td>6.1</td>\n",
       "      <td>5.284127</td>\n",
       "      <td>6.903955</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23495</th>\n",
       "      <td>121</td>\n",
       "      <td>1075</td>\n",
       "      <td>5</td>\n",
       "      <td>19.0</td>\n",
       "      <td>8.103093</td>\n",
       "      <td>8.121951</td>\n",
       "      <td>5.850000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23496</th>\n",
       "      <td>130</td>\n",
       "      <td>1203</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.440841</td>\n",
       "      <td>7.369128</td>\n",
       "      <td>6.903226</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23497</th>\n",
       "      <td>129</td>\n",
       "      <td>1237</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.330365</td>\n",
       "      <td>6.715420</td>\n",
       "      <td>5.454545</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23498</th>\n",
       "      <td>114</td>\n",
       "      <td>1141</td>\n",
       "      <td>3</td>\n",
       "      <td>87.0</td>\n",
       "      <td>7.464696</td>\n",
       "      <td>7.177492</td>\n",
       "      <td>9.833333</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23499</th>\n",
       "      <td>123</td>\n",
       "      <td>1071</td>\n",
       "      <td>7</td>\n",
       "      <td>47.0</td>\n",
       "      <td>8.535494</td>\n",
       "      <td>7.381862</td>\n",
       "      <td>5.052632</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23500 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       actual_weight  declared_horse_weight  draw  win_odds  jockey_ave_rank  \\\n",
       "0                133                   1032     1       3.8         6.052910   \n",
       "1                133                   1075    13       8.0         5.825153   \n",
       "2                121                   1065     3       5.7         7.857759   \n",
       "3                132                   1222     2       6.1         4.179172   \n",
       "4                125                   1136     9       6.1         5.284127   \n",
       "...              ...                    ...   ...       ...              ...   \n",
       "23495            121                   1075     5      19.0         8.103093   \n",
       "23496            130                   1203     1      17.0         7.440841   \n",
       "23497            129                   1237     2      18.0         7.330365   \n",
       "23498            114                   1141     3      87.0         7.464696   \n",
       "23499            123                   1071     7      47.0         8.535494   \n",
       "\n",
       "       trainer_ave_rank  recent_ave_rank  race_distance  \n",
       "0              7.381862         1.000000           1400  \n",
       "1              6.611465         2.000000           1400  \n",
       "2              6.888713         3.000000           1400  \n",
       "3              6.680328         4.000000           1400  \n",
       "4              6.903955         5.000000           1400  \n",
       "...                 ...              ...            ...  \n",
       "23495          8.121951         5.850000           1000  \n",
       "23496          7.369128         6.903226           1000  \n",
       "23497          6.715420         5.454545           1000  \n",
       "23498          7.177492         9.833333           1000  \n",
       "23499          7.381862         5.052632           1000  \n",
       "\n",
       "[23500 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train0 = training['finish_time']\n",
    "y_train = []\n",
    "for i in range(len(y_train0)):\n",
    "    sep = y_train0[i].split('.')\n",
    "    y_train.append(int(sep[0]) * 60 + int(sep[1]) + int(sep[2]) / 100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = testing[['actual_weight','declared_horse_weight','draw','win_odds','jockey_ave_rank','trainer_ave_rank',\n",
    "'recent_ave_rank','race_distance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = []\n",
    "y_test0 = testing['finish_time']\n",
    "for i in range(len(y_test0)):\n",
    "    sep = y_test0[i].split('.')\n",
    "    y_test.append(int(sep[0]) * 60 + int(sep[1]) + int(sep[2]) / 100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1_index = testing.index[testing['finishing_position']==1].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation:\n",
    "1. MSE\n",
    "2. Top_1: the percentage/probality when your prediction of top_1 horse(horse with shortest finish_time) for each race is actually the true top_1 horse.\n",
    "\n",
    "3. Top_3: percentage/probability when your prediction of top_1 horse for each race is actually within true top_3 horses for each race. \n",
    "\n",
    "4. Average_rank: the average true rank of top_1 horse based on your prediction over all races.\n",
    "\n",
    "For example, when you predict for 3 races and your predicted top_1 horse is actually ranking 1, 3, 5 in these races. Top_1 is 1/3, Top_3 is 2/3 and Average_Rank is 3.0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluation(predict):\n",
    "    top1_predict_index = []\n",
    "    for i in range(len(top1_index)-1):\n",
    "        temp = np.argmin(predict[top1_index[i]:top1_index[i + 1]])\n",
    "        top1_predict_index.append(top1_index[i] + temp)\n",
    "    temp0 = np.argmin(predict[top1_index[len(top1_index) - 1]:])\n",
    "    top1_predict_index.append(top1_index[len(top1_index) - 1] + temp0)\n",
    "\n",
    "    RMSE = math.sqrt(sum((np.array(predict) - np.array(y_test)) ** 2)) / len(y_test)\n",
    "    TOP_1 = float(len(set(top1_predict_index) & set(top1_index))) / len(top1_predict_index)\n",
    "\n",
    "    TOP_3 = (testing['finishing_position'][top1_predict_index].tolist().count(1) + testing['finishing_position'][top1_predict_index].tolist().count(2)\\\n",
    "          + testing['finishing_position'][top1_predict_index].tolist().count(3)) / float(len(top1_predict_index))\n",
    "    Average_Rank = sum(testing['finishing_position'][top1_predict_index]) / float(len(top1_predict_index))\n",
    "    return (RMSE,TOP_1,TOP_3,Average_Rank)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning parameters for SVR\n",
    "\n",
    "C is penalty parameter for error. If C is large, it means high penalty for error, which may cause overfitting; while if C is small, it means flat margins, which may cause under-fitting. Epsilon specifies the range of no-penalty district around margin. Larger epsilon means higher tolerance of error.\n",
    "\n",
    "Conducted small scale grid search for selection of C and epsilon. I tried values from 2^(-4) to 2^(2) for both C and epsilon, and I found C and epsilon actually do not have significant effect on the results with regard to 4 evaluation statistics. I choose the relative better pair of (C, epsilon)=( 2^(-2), 2^(-4) )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svr_model = SVR(kernel = 'linear', C = math.pow(2,-2), epsilon = math.pow(2,-4))\n",
    "# svr_model.fit(X_train, y_train)\n",
    "# svr_predict = svr_model.predict(X_test)\n",
    "# print('Evaluation statistics for SVR model:',Evaluation(svr_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###---Normalization----###\n",
    "\n",
    "# scaler = StandardScaler().fit(X_train)\n",
    "# X_train_trans = scaler.transform(X_train)\n",
    "# yy = pd.DataFrame()\n",
    "# yy['finish_time'] = y_train\n",
    "# scaler1 = StandardScaler().fit(yy)\n",
    "# y_train_trans = scaler1.transform(yy)\n",
    "# X_test_trans = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fit normalized data to svr_model\n",
    "# svr_model.fit(X_train_trans,y_train_trans)\n",
    "# svr_predict_norm = svr_model.predict(X_test_trans)\n",
    "# svr_norm_evaluation = Evaluation(svr_predict_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use training data mean and variance to get RMSE after normalization\n",
    "# y_test_norm = (np.array(y_test)-scaler1.mean_) / math.sqrt(scaler1.var_)\n",
    "# svr_norm_RMSE = math.sqrt(sum((np.array(svr_predict_norm) - y_test_norm) ** 2)) / len(y_test)\n",
    "# print('Normalized evaluation statistics for SVR model:',(svr_norm_RMSE,) + svr_norm_evaluation[1:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Gradient Boosting Regression Tree Model (GBRT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting Regression Tree Model is a generalization of boosting technique to arbitrary differentiable loss functions.\n",
    "It is used here becauese of its natural handling of data of mixed type, great predictive power and robustness to outliers in output space (via robust loss functions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning Parameters for GBRT:\n",
    "Loss function: It has various loss functions including ls, lad, huber, quantile. Choose loss=’qunatile’, since for default values of other parameters, this loss function performs best according to TOP_1 and TOP_3 evaluation statistics.\n",
    "\n",
    "learning_rate: controls the contribution of each weak classifier (tree).\n",
    "\n",
    "n_estimators: represents the number of weak learners (tree). Since boosting combines the output of many weak classifiers, the larger n_estimators, the more robust the model is and the better results are.\n",
    "\n",
    "max_depth: maximum nodes of the tree\n",
    "\n",
    "I chose learning_rate = 0.01, n_estimators = 10, max_depth = 2, since I found by assigning these three values to parameters, TOP_1 = 0.99, TOP_3 = 1, which performs the best in predicting winner of horse races."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbrt_model = GradientBoostingRegressor(loss = 'quantile',learning_rate = 0.01, n_estimators = 10, max_depth = 2)\n",
    "gbrt_model.fit(X_train,y_train)\n",
    "gbrt_predict = gbrt_model.predict(X_test)\n",
    "print('Evaluation statistics for GBRT model:' , Evaluation(gbrt_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit normalized data to gbrt_model\n",
    "gbrt_model.fit(X_train_trans,y_train_trans)\n",
    "gbrt_predict_norm = gbrt_model.predict(X_test_trans)\n",
    "gbrt_norm_evaluation = Evaluation(gbrt_predict_norm)\n",
    "\n",
    "# use training data mean and variance to get RMSE after normalization\n",
    "gbrt_norm_RMSE = math.sqrt(sum((np.array(gbrt_predict_norm) - y_test_norm) ** 2)) / len(y_test)\n",
    "print('Normalized evaluation statistics for GBRT model:',(gbrt_norm_RMSE,) + gbrt_norm_evaluation[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pd.DataFrame()\n",
    "f['RaceID'] = testing['race_id']\n",
    "f['HorseID'] = testing['horse_id']\n",
    "f['svr_predict'] = svr_predict\n",
    "f['svr_predict_norm'] = svr_predict_norm\n",
    "f['gbrt_predict'] = gbrt_predict\n",
    "f['gbrt_predict_norm'] = gbrt_predict_norm\n",
    "f.to_csv('reg_prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V. Betting Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Betting strategy is to bet all $1 for the predicted winning horse for each race. \n",
    "\n",
    "Concretely, if our prediction is correct for the winning horse, we will receive $1 × odds money. \n",
    "\n",
    "Otherwise, we will lose $1. \n",
    "\n",
    "The final result is positive if we win some money and negative if we lose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 4 classification models, if there are more than 1 HorseWin in a race in predictions, I will choose the one with smallest odds, since as odds increase, winning probability decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = pd.read_csv('testing.csv')\n",
    "champion_index = testing[testing['HorseWin'] == 1].index.tolist()\n",
    "champion_odds = testing[testing['HorseWin'] == 1]['win_odds'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_range_in_list(li, min, max):\n",
    "    ctr = 0\n",
    "    for x in li:\n",
    "        if min <= x <= max:\n",
    "            ctr += 1\n",
    "    return ctr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ele_in_list(li, min, max):\n",
    "    ele = []\n",
    "    for x in li:\n",
    "        if min <= x <= max:\n",
    "            ele.append(x)\n",
    "    return ele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def betting_result(champion_odds,champion_index,prediction):\n",
    "    money=0\n",
    "    for i in range(len(champion_index)-1):\n",
    "        ctr= count_range_in_list(prediction,champion_index[i],champion_index[i+1]-1)\n",
    "        if ctr==0:\n",
    "            money=money-1\n",
    "        elif ctr==1:\n",
    "            money=money-1+champion_odds[i]\n",
    "        else:\n",
    "            ele_list=ele_in_list(prediction,champion_index[i],champion_index[i+1]-1)\n",
    "            if min(ele_list)==champion_index[i]:\n",
    "                money=money-1+champion_odds[i]\n",
    "            else:\n",
    "                money=money-1\n",
    "    ctr = count_range_in_list(prediction, champion_index[len(champion_index)-1],len(testing['HorseWin'])-1)\n",
    "    if ctr == 0:\n",
    "        money = money - 1\n",
    "    elif ctr == 1:\n",
    "        money = money - 1 + champion_odds[len(champion_index)-1]\n",
    "    else:\n",
    "        ele_list = ele_in_list(prediction, champion_index[len(champion_index)-1], len(testing['HorseWin'])-1)\n",
    "        if min(ele_list)==champion_index[len(champion_index)-1]:\n",
    "            money = money - 1 + champion_odds[len(champion_index)-1]\n",
    "        else:\n",
    "            money = money - 1\n",
    "    return money"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = pd.read_csv('lr_predictions.csv')\n",
    "lr_index = lr[lr['HorseWin'] == 1].index.tolist()\n",
    "print('Betting result for Logistic Regression model:',betting_result(champion_odds,champion_index,lr_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = pd.read_csv('nb_predictions.csv')\n",
    "nb_index = nb[nb['HorseWin'] == 1].index.tolist()\n",
    "print('Betting result for Naive Bayes model:', betting_result(champion_odds,champion_index,nb_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = pd.read_csv('rf_predictions.csv')\n",
    "rf_index = rf[rf['HorseWin'] == 1].index.tolist()\n",
    "print('Betting result for Random Forest model:',betting_result(champion_odds,champion_index,rf_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = pd.read_csv('svm_predictions.csv')\n",
    "svm_index = svm[svm['HorseWin'] == 1].index.tolist()\n",
    "print('Betting result for SVM model:',betting_result(champion_odds,champion_index,svm_index))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 4 regression models, I choose the horse with shortest predicted finish_time as the unique winning horse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(predict):\n",
    "    top1_predict_index = []\n",
    "    for i in range(len(champion_index)-1):\n",
    "        temp = np.argmin(predict[champion_index[i]:champion_index[i + 1]])\n",
    "        top1_predict_index.append(champion_index[i]+temp)\n",
    "    temp0 = np.argmin(predict[champion_index[len(champion_index) - 1]:])\n",
    "    top1_predict_index.append(champion_index[len(champion_index) - 1] + temp0)\n",
    "    return top1_predict_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_prediction = pd.read_csv('reg_prediction.csv')\n",
    "reg_svr = reg_prediction['svr_predict']\n",
    "reg_svr_norm = reg_prediction['svr_predict_norm']\n",
    "reg_gbrt = reg_prediction['gbrt_predict']\n",
    "reg_gbrt_norm = reg_prediction['gbrt_predict_norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_index = prediction(reg_svr)\n",
    "svr_norm_index = prediction(reg_svr_norm)\n",
    "gbrt_index = prediction(reg_gbrt)\n",
    "gbrt_norm_index = prediction(reg_gbrt_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Betting result for SVR model:',betting_result(champion_odds,champion_index,svr_index))\n",
    "print('Betting result for SVR (Normalized) model:',betting_result(champion_odds,champion_index,svr_norm_index))\n",
    "print('Betting result for GBRT model:',betting_result(champion_odds,champion_index,gbrt_index))\n",
    "print('Betting result for GBRT (Normalized) model:',betting_result(champion_odds,champion_index,gbrt_norm_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It seems 2 regression algorithms perform well and normalization improves performance of SVR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Improvement:\n",
    "\n",
    "I set threshold for the average rank and odds. For example, we only bet the horse whose odd is in the smallest 5, and recent_ave_rank is also in smallest 5. This means we decreases the risk of betting in horses with bad recent performance. If the horse cannot satisfy the criteria, we do not bet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imp_betting(champion_odds,champion_index,prediction):\n",
    "    money = 0\n",
    "    for i in range(len(champion_index) - 1):\n",
    "        ctr = count_range_in_list(prediction, champion_index[i], champion_index[i + 1] - 1)\n",
    "        if ctr >= 1:\n",
    "            temp_odds = testing['win_odds'].tolist()[champion_index[i]:champion_index[i + 1]]\n",
    "            temp_ave_rank = testing['recent_ave_rank'].tolist()[champion_index[i]:champion_index[i + 1]]\n",
    "            seq_odds = sorted(temp_odds)\n",
    "            seq_ave_rank = sorted(temp_ave_rank)\n",
    "            ele_list = ele_in_list(prediction,champion_index[i],champion_index[i+1]-1)\n",
    "            if (seq_odds.index(testing['win_odds'][ele_list[0]]) <= 5) and (seq_ave_rank.index(testing['recent_ave_rank'][ele_list[0]]) <= 5):\n",
    "                money = money - 1\n",
    "                if ele_list[0] == champion_index[i]:\n",
    "                    money = money + champion_odds[i]\n",
    "    return money\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Improved betting result for Logistic Regression model:',imp_betting(champion_odds,champion_index,lr_index))\n",
    "print('Improved betting result for Naive Bayes model:',imp_betting(champion_odds,champion_index,nb_index))\n",
    "print('Improved betting result for Random Forest model:',imp_betting(champion_odds,champion_index,rf_index))\n",
    "print('Improved betting result for SVR model:',imp_betting(champion_odds,champion_index,svr_index))\n",
    "print('Improved betting result fo GBRT model:',imp_betting(champion_odds,champion_index,gbrt_index))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, it seems that setting threshold cannot improve the results for those method whose results are already positive. It only decreases losses by decreasing risk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VI. Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Line Chart of Recent Racing Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the history racing result of some specific horse.\n",
    "\n",
    "Interactive: takes a horse ID as input, and outputs a line chart that shows the finishing positions of 6 recent races that the horse attended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linechart(horse_id):\n",
    "    recent_6_runs = training[training.horse_id == horse_id]['recent_6_runs'][-1:].tolist()[0]\n",
    "\n",
    "    recent_6_runs = list(map(int,recent_6_runs.split('/')))[::-1]\n",
    "    print(recent_6_runs)\n",
    "    game_id = training[training.horse_id == horse_id][['race_id']][-6:]\n",
    "    print(game_id)\n",
    "    plt.plot(game_id.iloc[:,0], recent_6_runs, marker = '+')\n",
    "    plt.xlabel('Game_id')\n",
    "    plt.ylabel('Ranks of recent 6 runs')\n",
    "    plt.title('Line Chart of recent 6 runs'+'- Horse ' + horse_id)\n",
    "    plt.ylim((0, 14))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv('training.csv')\n",
    "horse_id = 'S047'\n",
    "linechart(horse_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Scatter Plot of Win Rate and Number of Wins "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The x-axis is the win rate, and the y-axis is the number of wins. \n",
    "\n",
    "Set a threshold and label the name of the horses (or jockeys) who reach the threshold. E.g., if a horse’s win rate is larger than 0.5, and wins more than 4 games, then you should annotate the point of this horse with its name. \n",
    "\n",
    "Goal: to find the “best” horse and the “best” jockey. Intuitively, the “best” one should have a high win rate and have won a large number of games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv('training.csv')\n",
    "jockey = training.jockey.unique()\n",
    "a = pd.DataFrame()\n",
    "a['jockey'] = jockey\n",
    "a['no_win'] = 0\n",
    "a['win_rate'] = 0.0\n",
    "for i in range(len(jockey)):\n",
    "    ranks = training[training.jockey == jockey[i]]['finishing_position'].tolist()\n",
    "    a['no_win'][i] = ranks.count(1)\n",
    "    a['win_rate'][i] = ranks.count(1) / float(len(ranks))\n",
    "\n",
    "horse = training.horse_name.unique()\n",
    "b = pd.DataFrame()\n",
    "b['horse'] = horse\n",
    "b['no_win'] = 0\n",
    "b['win_rate'] = 0.0\n",
    "for i in range(len(jockey)):\n",
    "    ranks=training[training.horse_name == horse[i]]['finishing_position'].tolist()\n",
    "    b['no_win'][i] = ranks.count(1)\n",
    "    b['win_rate'][i] = ranks.count(1) / float(len(ranks))\n",
    "\n",
    "figure(num = None, figsize = (12, 12), dpi = 90, facecolor = 'w', edgecolor = 'k')\n",
    "plt.subplot(2,1,1)\n",
    "plt.scatter(a['win_rate'],a['no_win'],alpha = 0.3)\n",
    "plt.title('Scatter plot for jockeys')\n",
    "plt.xlabel('Win Rate')\n",
    "plt.ylabel('Number of Wins')\n",
    "for i in range(len(jockey)):\n",
    "    if a['no_win'][i] >= 10 and a['win_rate'][i] >= 0.06:\n",
    "        plt.annotate(a['jockey'][i],(a['win_rate'][i],a['no_win'][i]),size = 7)\n",
    "\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.scatter(b['win_rate'],b['no_win'],alpha=0.3)\n",
    "plt.title('Scatter plot for horses')\n",
    "plt.xlabel('Win Rate')\n",
    "plt.ylabel('Number of Wins')\n",
    "for i in range(len(horse)):\n",
    "    if b['no_win'][i] >= 2 and b['win_rate'][i] >= 0.15:\n",
    "        plt.annotate(b['horse'][i],(b['win_rate'][i],b['no_win'][i]),size = 7)\n",
    "        \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best jockey is J Moreira. Since he has the highest number of wins and very high win rate.\n",
    "\n",
    "\n",
    "The best horse is Romantic Cash, since it has the highest win rate and its ranks are very stable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Pie Chart of the Draw Bias Effect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pie chart is a way to visualize the distribution of categorical data\n",
    "\n",
    "#### Goal: explore the effect of draw bias in horse racing. \n",
    "\n",
    "The draw refers to the stall a horse will start the race from. The draw is normally chosen at random on the day the horses are declared to run. Obviously, the inside lane would hold an edge over the field as they have a shorter distance to the bend, in comparison to the other lanes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv('training.csv')\n",
    "\n",
    "win_prob = []\n",
    "for i in range(1,16,1):\n",
    "    win_prob.append(training[training.draw == i]['finishing_position'].tolist().count(1) / float(len(training[training.draw == i])))\n",
    "\n",
    "print(win_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['1','2','3','4','5','6','7','8','9','10','11','12','13','14','15']\n",
    "figure(num = None, figsize = (8, 8), dpi = 90, facecolor = 'w', edgecolor = 'k')\n",
    "plt.pie(win_prob,labels = labels,autopct = '%1.1f%%', colors = sns.color_palette(\"cubehelix\"))\n",
    "plt.title('Pie Chart of the Draw Bias Effect (Number represents No. of lane the horse will run)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Low draws indeed have a considerable advantage, as we can see that as draw increases, the winning probability decreases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Bar Chart of the Feature Importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use random forest classifier to evaluate the importance of the features, which measures how much each feature decreases the weighted impurity in a tree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv('training.csv')\n",
    "rf_model = RandomForestClassifier()\n",
    "X_train = training[['actual_weight','declared_horse_weight','draw','win_odds','jockey_ave_rank','trainer_ave_rank',\n",
    "'recent_ave_rank','race_distance']]\n",
    "y_train = training[['HorseWin','HorseRankTop3','HorseRankTop50Percent']]\n",
    "rf_model.fit(X_train,y_train['HorseWin'])\n",
    "features = 'actual_weight','declared_horse_weight','draw','win_odds','jockey_ave_rank','trainer_ave_rank','recent_ave_rank','race_distance'\n",
    "importance = rf_model.feature_importances_\n",
    "indices = np.argsort(importance)[::-1]\n",
    "print(importance[indices])\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(num = None, figsize = (8, 6), dpi = 90, facecolor = 'w', edgecolor = 'k')\n",
    "plt.bar(range(len(features)),importance[indices],color = sns.color_palette(\"RdBu_r\", 8))\n",
    "plt.xticks(range(len(features)),features)\n",
    "plt.xlabel('Feature names')\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Bar Chart of the Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We find that actual_weight, declared_horse_weight and draw affect the most, while race_distance has the least effect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Visualize SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it is hard to visualize high-dimensional data, for the input data X, we only consider these two features: recent_rank and jockey_ave_rank. Also, for the target y, we only care about whether the finishing position is in top 50%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv('training.csv')\n",
    "X = training[['recent_ave_rank','jockey_ave_rank']]\n",
    "y = training['HorseRankTop50Percent']\n",
    "svm_model = SVC(kernel = 'linear')\n",
    "svm_model.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_meshgrid(x, y, h = .02):\n",
    "\n",
    "    x_min, x_max = x.min() - 1, x.max() + 1\n",
    "    y_min, y_max = y.min() - 1, y.max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    return xx, yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_contours(clf, xx, yy, **params):\n",
    "\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    out = plt.contourf(xx, yy, Z, **params)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0, X1 = X['recent_ave_rank'], X['jockey_ave_rank']\n",
    "xx, yy = make_meshgrid(X0, X1)\n",
    "\n",
    "figure(num = None, figsize = (8, 6), dpi = 90, facecolor = 'w', edgecolor = 'k')\n",
    "plot_contours(svm_model,xx, yy, alpha = 0.8)\n",
    "plt.scatter(X0, X1, c = y,  s = 20, edgecolors = 'k')\n",
    "plt.title('Visualized SVM')\n",
    "plt.xlabel('Recent average rank')\n",
    "plt.ylabel('Jockey average rank')\n",
    "patch = mpatches.Patch(color = 'purple',label = 'SVC(kernel=\\'linear\\')')\n",
    "plt.legend(handles = [patch])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear kernel seems not bad in two-feature SVM classification. But there are still plenty of points cross the margin which cannot be classified correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
