{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V. Betting Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Betting strategy is to bet all $1 for the predicted winning horse for each race. \n",
    "\n",
    "Concretely, if our prediction is correct for the winning horse, we will receive $1 × odds money. \n",
    "\n",
    "Otherwise, we will lose $1. \n",
    "\n",
    "The final result is positive if we win some money and negative if we lose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 4 classification models, if there are more than 1 HorseWin in a race in predictions, I will choose the one with smallest odds, since as odds increase, winning probability decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = pd.read_csv('testing.csv')\n",
    "champion_index = testing[testing['HorseWin'] == 1].index.tolist()\n",
    "champion_odds = testing[testing['HorseWin'] == 1]['win_odds'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_range_in_list(li, min, max):\n",
    "    ctr = 0\n",
    "    for x in li:\n",
    "        if min <= x <= max:\n",
    "            ctr += 1\n",
    "    return ctr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ele_in_list(li, min, max):\n",
    "    ele = []\n",
    "    for x in li:\n",
    "        if min <= x <= max:\n",
    "            ele.append(x)\n",
    "    return ele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def betting_result(champion_odds,champion_index,prediction):\n",
    "    money=0\n",
    "    for i in range(len(champion_index)-1):\n",
    "        ctr= count_range_in_list(prediction,champion_index[i],champion_index[i+1]-1)\n",
    "        if ctr==0:\n",
    "            money=money-1\n",
    "        elif ctr==1:\n",
    "            money=money-1+champion_odds[i]\n",
    "        else:\n",
    "            ele_list=ele_in_list(prediction,champion_index[i],champion_index[i+1]-1)\n",
    "            if min(ele_list)==champion_index[i]:\n",
    "                money=money-1+champion_odds[i]\n",
    "            else:\n",
    "                money=money-1\n",
    "    ctr = count_range_in_list(prediction, champion_index[len(champion_index)-1],len(testing['HorseWin'])-1)\n",
    "    if ctr == 0:\n",
    "        money = money - 1\n",
    "    elif ctr == 1:\n",
    "        money = money - 1 + champion_odds[len(champion_index)-1]\n",
    "    else:\n",
    "        ele_list = ele_in_list(prediction, champion_index[len(champion_index)-1], len(testing['HorseWin'])-1)\n",
    "        if min(ele_list)==champion_index[len(champion_index)-1]:\n",
    "            money = money - 1 + champion_odds[len(champion_index)-1]\n",
    "        else:\n",
    "            money = money - 1\n",
    "    return money"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Betting result for Logistic Regression model: -449.9\n"
     ]
    }
   ],
   "source": [
    "lr = pd.read_csv('lr_predictions.csv')\n",
    "lr_index = lr[lr['HorseWin'] == 1].index.tolist()\n",
    "print('Betting result for Logistic Regression model:',betting_result(champion_odds,champion_index,lr_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Betting result for Naive Bayes model: 1554.5999999999992\n"
     ]
    }
   ],
   "source": [
    "nb = pd.read_csv('nb_predictions.csv')\n",
    "nb_index = nb[nb['HorseWin'] == 1].index.tolist()\n",
    "print('Betting result for Naive Bayes model:', betting_result(champion_odds,champion_index,nb_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Betting result for Random Forest model: 44.59999999999998\n"
     ]
    }
   ],
   "source": [
    "rf = pd.read_csv('rf_predictions.csv')\n",
    "rf_index = rf[rf['HorseWin'] == 1].index.tolist()\n",
    "print('Betting result for Random Forest model:',betting_result(champion_odds,champion_index,rf_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 4 regression models, I choose the horse with shortest predicted finish_time as the unique winning horse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(predict):\n",
    "    top1_predict_index = []\n",
    "    for i in range(len(champion_index)-1):\n",
    "        temp = np.argmin(predict[champion_index[i]:champion_index[i + 1]])\n",
    "        top1_predict_index.append(champion_index[i]+temp)\n",
    "    temp0 = np.argmin(predict[champion_index[len(champion_index) - 1]:])\n",
    "    top1_predict_index.append(champion_index[len(champion_index) - 1] + temp0)\n",
    "    return top1_predict_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'gbrt_predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\finan\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3360\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\finan\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\finan\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'gbrt_predict'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15696/2806017857.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#reg_svr = reg_prediction['svr_predict']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#reg_svr_norm = reg_prediction['svr_predict_norm']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mreg_gbrt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreg_prediction\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'gbrt_predict'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m#reg_gbrt_norm = reg_prediction['gbrt_predict_norm']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\finan\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3456\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3457\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3458\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3459\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\finan\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3361\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3363\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'gbrt_predict'"
     ]
    }
   ],
   "source": [
    "reg_prediction = pd.read_csv('gnb_pred.csv')\n",
    "#reg_svr = reg_prediction['svr_predict']\n",
    "#reg_svr_norm = reg_prediction['svr_predict_norm']\n",
    "reg_gbrt = reg_prediction['gbrt_predict']\n",
    "#reg_gbrt_norm = reg_prediction['gbrt_predict_norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_index = prediction(reg_svr)\n",
    "svr_norm_index = prediction(reg_svr_norm)\n",
    "gbrt_index = prediction(reg_gbrt)\n",
    "gbrt_norm_index = prediction(reg_gbrt_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Betting result for SVR model:',betting_result(champion_odds,champion_index,svr_index))\n",
    "print('Betting result for SVR (Normalized) model:',betting_result(champion_odds,champion_index,svr_norm_index))\n",
    "print('Betting result for GBRT model:',betting_result(champion_odds,champion_index,gbrt_index))\n",
    "print('Betting result for GBRT (Normalized) model:',betting_result(champion_odds,champion_index,gbrt_norm_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It seems 2 regression algorithms perform well and normalization improves performance of SVR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Improvement:\n",
    "\n",
    "I set threshold for the average rank and odds. For example, we only bet the horse whose odd is in the smallest 5, and recent_ave_rank is also in smallest 5. This means we decreases the risk of betting in horses with bad recent performance. If the horse cannot satisfy the criteria, we do not bet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imp_betting(champion_odds,champion_index,prediction):\n",
    "    money = 0\n",
    "    for i in range(len(champion_index) - 1):\n",
    "        ctr = count_range_in_list(prediction, champion_index[i], champion_index[i + 1] - 1)\n",
    "        if ctr >= 1:\n",
    "            temp_odds = testing['win_odds'].tolist()[champion_index[i]:champion_index[i + 1]]\n",
    "            temp_ave_rank = testing['recent_ave_rank'].tolist()[champion_index[i]:champion_index[i + 1]]\n",
    "            seq_odds = sorted(temp_odds)\n",
    "            seq_ave_rank = sorted(temp_ave_rank)\n",
    "            ele_list = ele_in_list(prediction,champion_index[i],champion_index[i+1]-1)\n",
    "            if (seq_odds.index(testing['win_odds'][ele_list[0]]) <= 5) and (seq_ave_rank.index(testing['recent_ave_rank'][ele_list[0]]) <= 5):\n",
    "                money = money - 1\n",
    "                if ele_list[0] == champion_index[i]:\n",
    "                    money = money + champion_odds[i]\n",
    "    return money\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Improved betting result for Logistic Regression model:',imp_betting(champion_odds,champion_index,lr_index))\n",
    "print('Improved betting result for Naive Bayes model:',imp_betting(champion_odds,champion_index,nb_index))\n",
    "print('Improved betting result for Random Forest model:',imp_betting(champion_odds,champion_index,rf_index))\n",
    "print('Improved betting result for SVR model:',imp_betting(champion_odds,champion_index,svr_index))\n",
    "print('Improved betting result fo GBRT model:',imp_betting(champion_odds,champion_index,gbrt_index))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, it seems that setting threshold cannot improve the results for those method whose results are already positive. It only decreases losses by decreasing risk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VI. Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Line Chart of Recent Racing Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the history racing result of some specific horse.\n",
    "\n",
    "Interactive: takes a horse ID as input, and outputs a line chart that shows the finishing positions of 6 recent races that the horse attended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linechart(horse_id):\n",
    "    recent_6_runs = training[training.horse_id == horse_id]['recent_6_runs'][-1:].tolist()[0]\n",
    "\n",
    "    recent_6_runs = list(map(int,recent_6_runs.split('/')))[::-1]\n",
    "    print(recent_6_runs)\n",
    "    game_id = training[training.horse_id == horse_id][['race_id']][-6:]\n",
    "    print(game_id)\n",
    "    plt.plot(game_id.iloc[:,0], recent_6_runs, marker = '+')\n",
    "    plt.xlabel('Game_id')\n",
    "    plt.ylabel('Ranks of recent 6 runs')\n",
    "    plt.title('Line Chart of recent 6 runs'+'- Horse ' + horse_id)\n",
    "    plt.ylim((0, 14))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv('training.csv')\n",
    "horse_id = 'S047'\n",
    "linechart(horse_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Scatter Plot of Win Rate and Number of Wins "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The x-axis is the win rate, and the y-axis is the number of wins. \n",
    "\n",
    "Set a threshold and label the name of the horses (or jockeys) who reach the threshold. E.g., if a horse’s win rate is larger than 0.5, and wins more than 4 games, then you should annotate the point of this horse with its name. \n",
    "\n",
    "Goal: to find the “best” horse and the “best” jockey. Intuitively, the “best” one should have a high win rate and have won a large number of games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv('training.csv')\n",
    "jockey = training.jockey.unique()\n",
    "a = pd.DataFrame()\n",
    "a['jockey'] = jockey\n",
    "a['no_win'] = 0\n",
    "a['win_rate'] = 0.0\n",
    "for i in range(len(jockey)):\n",
    "    ranks = training[training.jockey == jockey[i]]['finishing_position'].tolist()\n",
    "    a['no_win'][i] = ranks.count(1)\n",
    "    a['win_rate'][i] = ranks.count(1) / float(len(ranks))\n",
    "\n",
    "horse = training.horse_name.unique()\n",
    "b = pd.DataFrame()\n",
    "b['horse'] = horse\n",
    "b['no_win'] = 0\n",
    "b['win_rate'] = 0.0\n",
    "for i in range(len(jockey)):\n",
    "    ranks=training[training.horse_name == horse[i]]['finishing_position'].tolist()\n",
    "    b['no_win'][i] = ranks.count(1)\n",
    "    b['win_rate'][i] = ranks.count(1) / float(len(ranks))\n",
    "\n",
    "figure(num = None, figsize = (12, 12), dpi = 90, facecolor = 'w', edgecolor = 'k')\n",
    "plt.subplot(2,1,1)\n",
    "plt.scatter(a['win_rate'],a['no_win'],alpha = 0.3)\n",
    "plt.title('Scatter plot for jockeys')\n",
    "plt.xlabel('Win Rate')\n",
    "plt.ylabel('Number of Wins')\n",
    "for i in range(len(jockey)):\n",
    "    if a['no_win'][i] >= 10 and a['win_rate'][i] >= 0.06:\n",
    "        plt.annotate(a['jockey'][i],(a['win_rate'][i],a['no_win'][i]),size = 7)\n",
    "\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.scatter(b['win_rate'],b['no_win'],alpha=0.3)\n",
    "plt.title('Scatter plot for horses')\n",
    "plt.xlabel('Win Rate')\n",
    "plt.ylabel('Number of Wins')\n",
    "for i in range(len(horse)):\n",
    "    if b['no_win'][i] >= 2 and b['win_rate'][i] >= 0.15:\n",
    "        plt.annotate(b['horse'][i],(b['win_rate'][i],b['no_win'][i]),size = 7)\n",
    "        \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best jockey is J Moreira. Since he has the highest number of wins and very high win rate.\n",
    "\n",
    "\n",
    "The best horse is Romantic Cash, since it has the highest win rate and its ranks are very stable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Pie Chart of the Draw Bias Effect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pie chart is a way to visualize the distribution of categorical data\n",
    "\n",
    "#### Goal: explore the effect of draw bias in horse racing. \n",
    "\n",
    "The draw refers to the stall a horse will start the race from. The draw is normally chosen at random on the day the horses are declared to run. Obviously, the inside lane would hold an edge over the field as they have a shorter distance to the bend, in comparison to the other lanes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv('training.csv')\n",
    "\n",
    "win_prob = []\n",
    "for i in range(1,16,1):\n",
    "    win_prob.append(training[training.draw == i]['finishing_position'].tolist().count(1) / float(len(training[training.draw == i])))\n",
    "\n",
    "print(win_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['1','2','3','4','5','6','7','8','9','10','11','12','13','14','15']\n",
    "figure(num = None, figsize = (8, 8), dpi = 90, facecolor = 'w', edgecolor = 'k')\n",
    "plt.pie(win_prob,labels = labels,autopct = '%1.1f%%', colors = sns.color_palette(\"cubehelix\"))\n",
    "plt.title('Pie Chart of the Draw Bias Effect (Number represents No. of lane the horse will run)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Low draws indeed have a considerable advantage, as we can see that as draw increases, the winning probability decreases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Bar Chart of the Feature Importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use random forest classifier to evaluate the importance of the features, which measures how much each feature decreases the weighted impurity in a tree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv('training.csv')\n",
    "rf_model = RandomForestClassifier()\n",
    "X_train = training[['actual_weight','declared_horse_weight','draw','win_odds','jockey_ave_rank','trainer_ave_rank',\n",
    "'recent_ave_rank','race_distance']]\n",
    "y_train = training[['HorseWin','HorseRankTop3','HorseRankTop50Percent']]\n",
    "rf_model.fit(X_train,y_train['HorseWin'])\n",
    "features = 'actual_weight','declared_horse_weight','draw','win_odds','jockey_ave_rank','trainer_ave_rank','recent_ave_rank','race_distance'\n",
    "importance = rf_model.feature_importances_\n",
    "indices = np.argsort(importance)[::-1]\n",
    "print(importance[indices])\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(num = None, figsize = (8, 6), dpi = 90, facecolor = 'w', edgecolor = 'k')\n",
    "plt.bar(range(len(features)),importance[indices],color = sns.color_palette(\"RdBu_r\", 8))\n",
    "plt.xticks(range(len(features)),features)\n",
    "plt.xlabel('Feature names')\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Bar Chart of the Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We find that actual_weight, declared_horse_weight and draw affect the most, while race_distance has the least effect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Visualize SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it is hard to visualize high-dimensional data, for the input data X, we only consider these two features: recent_rank and jockey_ave_rank. Also, for the target y, we only care about whether the finishing position is in top 50%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv('training.csv')\n",
    "X = training[['recent_ave_rank','jockey_ave_rank']]\n",
    "y = training['HorseRankTop50Percent']\n",
    "svm_model = SVC(kernel = 'linear')\n",
    "svm_model.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_meshgrid(x, y, h = .02):\n",
    "\n",
    "    x_min, x_max = x.min() - 1, x.max() + 1\n",
    "    y_min, y_max = y.min() - 1, y.max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    return xx, yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_contours(clf, xx, yy, **params):\n",
    "\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    out = plt.contourf(xx, yy, Z, **params)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0, X1 = X['recent_ave_rank'], X['jockey_ave_rank']\n",
    "xx, yy = make_meshgrid(X0, X1)\n",
    "\n",
    "figure(num = None, figsize = (8, 6), dpi = 90, facecolor = 'w', edgecolor = 'k')\n",
    "plot_contours(svm_model,xx, yy, alpha = 0.8)\n",
    "plt.scatter(X0, X1, c = y,  s = 20, edgecolors = 'k')\n",
    "plt.title('Visualized SVM')\n",
    "plt.xlabel('Recent average rank')\n",
    "plt.ylabel('Jockey average rank')\n",
    "patch = mpatches.Patch(color = 'purple',label = 'SVC(kernel=\\'linear\\')')\n",
    "plt.legend(handles = [patch])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear kernel seems not bad in two-feature SVM classification. But there are still plenty of points cross the margin which cannot be classified correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "fc902f5f9f1b4ac8244fa2d1a71d10e1bb8b95bd909217946ac119cb82bcf206"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
